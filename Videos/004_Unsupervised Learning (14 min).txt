
In this video, we'll talk about
the second major type of machine
learning problem, called Unsupervised Learning.
In the last video, we talked about Supervised Learning.
Back then, recall data sets
that look like this, where each
example was labeled either
as a positive or negative example,
whether it was a benign or a malignant tumor.
So for each example in Supervised
Learning, we were told explicitly what
is the so-called right answer,
whether it's benign or malignant.
In Unsupervised Learning, we're given
data that looks different
than data that looks like
this that doesn't have
any labels or that all
has the same label or really no labels.
So we're given the data set and
we're not told what to
do with it and we're not
told what each data point is.
Instead we're just told, here is a data set.
Can you find some structure in the data?
Given this data set, an
Unsupervised Learning algorithm might decide that
the data lives in two different clusters.
And so there's one cluster
and there's a different cluster.
And yes, Supervised Learning algorithm may
break these data into these two separate clusters.
So this is called a clustering algorithm.
And this turns out to be used in many places.
One example where clustering
is used is in Google
News and if you have not
seen this before, you can actually
go to this URL news.google.com
to take a look.
What Google News does is everyday
it goes and looks at tens
of thousands or hundreds of
thousands of new stories on the
web and it groups them into cohesive news stories.
For example, let's look here.
The URLs here link
to different news stories
about the BP Oil Well story.
So, let's click on
one of these URL's and we'll
click on one of these URL's.
What I'll get to is a web page like this.
Here's a Wall Street
Journal article about, you know, the BP
Oil Well Spill stories of
"BP Kills Macondo",
which is a name of the
spill and if you
click on a different URL
from that group then you might get the different story.
Here's the CNN story about a
game, the BP Oil Spill,
and if you click on yet
a third link, then you might get a different story.
Here's the UK Guardian story
about the BP Oil Spill.
So what Google News has done
is look for tens of thousands of
news stories and automatically cluster them together.
So, the news stories that are all
about the same topic get displayed together.
It turns out that
clustering algorithms and Unsupervised Learning
algorithms are used in many other problems as well.
Here's one on understanding genomics.
Here's an example of DNA microarray data.
The idea is put
a group of different individuals and
for each of them, you measure
how much they do or do not have a certain gene.
Technically you measure how much certain genes are expressed.
So these colors, red, green,
gray and so on, they
show the degree to which
different individuals do or
do not have a specific gene.
And what you can do is then
run a clustering algorithm to group
individuals into different categories
or into different types of people.
So this is Unsupervised Learning because
we're not telling the algorithm in advance
that these are type 1 people,
those are type 2 persons, those
are type 3 persons and so
on and instead what were saying is yeah here's a bunch of data.
I don't know what's in this data.
I don't know who's and what type.
I don't even know what the different
types of people are, but can
you automatically find structure in
the data from the you automatically
cluster the individuals into these types
that I don't know in advance?
Because we're not giving the algorithm
the right answer for the
examples in my data
set, this is Unsupervised Learning.
Unsupervised Learning or clustering is used for a bunch of other applications.
It's used to organize large computer clusters.
I had some friends looking at
large data centers, that is
large computer clusters and trying
to figure out which machines tend to
work together and if
you can put those machines together,
you can make your data center work more efficiently.
This second application is on social network analysis.
So given knowledge about which friends
you email the most or
given your Facebook friends or
your Google+ circles, can
we automatically identify which are
cohesive groups of friends,
also which are groups of people
that all know each other?
Market segmentation.
Many companies have huge databases of customer information.
So, can you look at this
customer data set and automatically
discover market segments and automatically
group your customers into different
market segments so that
you can automatically and more
efficiently sell or market
your different market segments together?
Again, this is Unsupervised Learning
because we have all this
customer data, but we don't
know in advance what are the
market segments and for
the customers in our data
set, you know, we don't know in
advance who is in
market segment one, who is
in market segment two, and so on.
But we have to let the algorithm discover all this just from the data.
Finally, it turns out that Unsupervised
Learning is also used for
surprisingly astronomical data analysis
and these clustering algorithms gives
surprisingly interesting useful theories
of how galaxies are born.
All of these are examples of clustering,
which is just one type of Unsupervised Learning.
Let me tell you about another one.
I'm gonna tell you about the cocktail party problem.
So, you've been to cocktail parties before, right?
Well, you can imagine there's a
party, room full of people, all
sitting around, all talking at the
same time and there are
all these overlapping voices because everyone
is talking at the same time, and
it is almost hard to hear the person in front of you.
So maybe at a
cocktail party with two people,
two people talking at the same
time, and it's a somewhat
small cocktail party.
And we're going to put two
microphones in the room so
there are microphones, and because
these microphones are at two
different distances from the
speakers, each microphone records
a different combination of these two speaker voices.
Maybe speaker one is a
little louder in microphone one
and maybe speaker two is a
little bit louder on microphone 2
because the 2 microphones are
at different positions relative to
the 2 speakers, but each
microphone would cause an overlapping
combination of both speakers' voices.
So here's an actual recording
of two speakers recorded by a researcher.
Let me play for you the
first, what the first microphone sounds like.
One (uno), two (dos),
three (tres), four (cuatro), five
(cinco), six (seis), seven (siete),
eight (ocho), nine (nueve), ten (y diez).
All right, maybe not the most interesting cocktail
party, there's two people
counting from one to ten
in two languages but you know.
What you just heard was the
first microphone recording, here's the second recording.
Uno (one), dos (two), tres (three), cuatro
(four), cinco (five), seis (six), siete (seven),
ocho (eight), nueve (nine) y diez (ten).
So we can do, is take
these two microphone recorders and give
them to an Unsupervised Learning algorithm
called the cocktail party algorithm,
and tell the algorithm
- find structure in this data for you.
And what the algorithm will do
is listen to these
audio recordings and say, you
know it sounds like the
two audio recordings are being
added together or that have being
summed together to produce these recordings that we had.
Moreover, what the cocktail party
algorithm will do is separate
out these two audio sources
that were being added or being
summed together to form other
recordings and, in fact,
here's the first output of the cocktail party algorithm.
One, two, three, four,
five, six, seven, eight, nine, ten.
So, I separated out the English
voice in one of the recordings.
And here's the second of it.
Uno, dos, tres, quatro, cinco,
seis, siete, ocho, nueve y diez.
Not too bad, to give you
one more example, here's another
recording of another similar situation,
here's the first microphone :  One,
two, three, four, five, six,
seven, eight, nine, ten.
OK so the poor guy's gone
home from the cocktail party and
he 's now sitting in a room by himself talking to his radio.
Here's the second microphone recording.
One, two, three, four, five, six, seven, eight, nine, ten.
When you give these two microphone
recordings to the same algorithm,
what it does, is again say,
you know, it sounds like there
are two audio sources, and moreover,
the album says, here is
the first of the audio sources I found.
One, two, three, four,
five, six, seven, eight, nine, ten.
So that wasn't perfect, it
got the voice, but it
also got a little bit of the music in there.
Then here's the second output to the algorithm.
Not too bad, in that second
output it managed to get rid of the voice entirely.
And just, you know,
cleaned up the music, got rid of the counting from one to ten.
So you might look at
an Unsupervised Learning algorithm like
this and ask how
complicated this is to implement this, right?
It seems like in order to,
you know, build this application, it seems
like to do this audio processing you
need to write a ton of code
or maybe link into like a
bunch of synthesizer Java libraries that
process audio, seems like
a really complicated program, to do
this audio, separating out audio and so on.
It turns out the algorithm, to
do what you just heard, that
can be done with one line
of code - shown right here.
It take researchers a long
time to come up with this line of code.
I'm not saying this is an easy problem,
But it turns out that when you
use the right programming environment, many learning
algorithms can be really short programs.
So this is also why in
this class we're going to
use the Octave programming environment.
Octave, is free open source
software, and using a
tool like Octave or Matlab,
many learning algorithms become just
a few lines of code to implement.
Later in this class, I'll just teach
you a little bit about how to
use Octave and you'll be
implementing some of these algorithms in Octave.
Or if you have Matlab you can use that too.
It turns out the Silicon Valley, for
a lot of machine learning algorithms,
what we do is first prototype
our software in Octave because software
in Octave makes it incredibly fast
to implement these learning algorithms.
Here each of these functions
like for example the SVD
function that stands for singular
value decomposition; but that turns
out to be a
linear algebra routine, that is just built into Octave.
If you were trying to do this
in C++ or Java,
this would be many many lines of
code linking complex C++ or Java libraries.
So, you can implement this stuff as
C++ or Java
or Python, it's just much
more complicated to do so in those languages.
What I've seen after having taught
machine learning for almost a
decade now, is that, you
learn much faster if you
use Octave as your
programming environment, and if
you use Octave as your
learning tool and as your
prototyping tool, it'll let
you learn and prototype learning algorithms much more quickly.
And in fact what many people will
do to in the large Silicon
Valley companies is in fact, use
an algorithm like Octave to first
prototype the learning algorithm, and
only after you've gotten it
to work, then you migrate
it to C++ or Java or whatever.
It turns out that by doing
things this way, you can often
get your algorithm to work much
faster than if you were starting out in C++.
So, I know that as an
instructor, I get to
say "trust me on
this one" only a finite
number of times, but for
those of you who've never used these
Octave type programming environments before,
I am going to ask you
to trust me on this one,
and say that you, you will,
I think your time, your development
time is one of the most valuable resources.
And having seen lots
of people do this, I think
you as a machine learning
researcher, or machine learning developer
will be much more productive if
you learn to start in prototype,
to start in Octave, in some other language.
Finally, to wrap
up this video, I have one quick review question for you.
We talked about Unsupervised Learning, which
is a learning setting where you
give the algorithm a ton
of data and just ask it
to find structure in the data for us.
Of the following four examples, which
ones, which of these four
do you think would will be
an Unsupervised Learning algorithm as
opposed to Supervised Learning problem.
For each of the four
check boxes on the left,
check the ones for which
you think Unsupervised Learning
algorithm would be appropriate and
then click the button on the lower right to check your answer.
So when the video pauses, please
answer the question on the slide.
So, hopefully, you've remembered the spam folder problem.
If you have labeled data, you
know, with spam and
non-spam e-mail, we'd treat this as a Supervised Learning problem.
The news story example, that's
exactly the Google News example
that we saw in this video,
we saw how you can use
a clustering algorithm to cluster
these articles together so that's Unsupervised Learning.
The market segmentation example I
talked a little bit earlier, you
can do that as an Unsupervised Learning problem
because I am just gonna
get my algorithm data and ask
it to discover market segments automatically.
And the final example, diabetes, well,
that's actually just like our
breast cancer example from the last video.
Only instead of, you know,
good and bad cancer tumors or
benign or malignant tumors we
instead have diabetes or
not and so we will
use that as a supervised,
we will solve that as
a Supervised Learning problem just like
we did for the breast tumor data.
So, that's it for Unsupervised
Learning and in the
next video, we'll delve more
into specific learning algorithms
and start to talk about
just how these algorithms work and
how we can, how you can go about implementing them.
