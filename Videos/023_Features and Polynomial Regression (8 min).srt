
1
00:00:00,020 --> 00:00:02,074
You now know about linear regression with multiple variables.

2
00:00:03,091 --> 00:00:04,096
In this video, I wanna tell

3
00:00:05,016 --> 00:00:06,000
you a bit about the choice

4
00:00:06,037 --> 00:00:07,062
of features that you have and

5
00:00:07,076 --> 00:00:09,044
how you can get different learning

6
00:00:09,075 --> 00:00:11,000
algorithm, sometimes very powerful

7
00:00:11,047 --> 00:00:12,088
ones by choosing appropriate features.

8
00:00:13,081 --> 00:00:14,085
And in particular I also want

9
00:00:15,021 --> 00:00:17,037
to tell you about polynomial regression allows

10
00:00:17,080 --> 00:00:19,035
you to use the machinery of

11
00:00:19,050 --> 00:00:20,096
linear regression to fit very

12
00:00:21,023 --> 00:00:23,026
complicated, even very non-linear functions.

13
00:00:25,069 --> 00:00:28,014
Let's take the example of predicting the price of the house.

14
00:00:29,030 --> 00:00:30,026
Suppose you have two features,

15
00:00:31,012 --> 00:00:33,042
the frontage of house and the depth of the house.

16
00:00:33,077 --> 00:00:35,032
So, here's the picture of the house we're trying to sell.

17
00:00:35,039 --> 00:00:37,010
So, the frontage is

18
00:00:37,024 --> 00:00:38,049
defined as this distance

19
00:00:40,038 --> 00:00:42,064
is basically the width

20
00:00:42,096 --> 00:00:44,057
or the length of

21
00:00:44,096 --> 00:00:46,039
how wide your lot

22
00:00:46,064 --> 00:00:47,084
is if this that you

23
00:00:48,002 --> 00:00:49,013
own, and the depth

24
00:00:49,050 --> 00:00:52,032
of the house is how

25
00:00:53,013 --> 00:00:54,061
deep your property is, so

26
00:00:54,077 --> 00:00:57,010
there's a frontage, there's a depth.

27
00:00:58,013 --> 00:00:59,054
called frontage and depth.

28
00:00:59,082 --> 00:01:00,093
You might build a linear regression

29
00:01:01,035 --> 00:01:03,064
model like this where frontage

30
00:01:04,018 --> 00:01:05,079
is your first feature x1 and

31
00:01:06,003 --> 00:01:07,012
your depth is your second

32
00:01:07,051 --> 00:01:10,000
feature x2, but when you're

33
00:01:10,014 --> 00:01:11,051
applying linear regression, you don't

34
00:01:11,076 --> 00:01:12,084
necessarily have to use

35
00:01:13,034 --> 00:01:15,073
just the features x1 and x2 that you're given.

36
00:01:16,060 --> 00:01:19,029
What you can do is actually create new features by yourself.

37
00:01:20,053 --> 00:01:21,054
So, if I want to predict

38
00:01:21,070 --> 00:01:22,070
the price of a house, what I

39
00:01:22,087 --> 00:01:24,043
might do instead is decide

40
00:01:24,084 --> 00:01:26,032
that what really determines

41
00:01:27,048 --> 00:01:28,081
the size of the house is

42
00:01:29,009 --> 00:01:31,001
the area or the land area that I own.

43
00:01:32,018 --> 00:01:32,098
So, I might create a new feature.

44
00:01:33,037 --> 00:01:34,023
I'm just gonna call this feature

45
00:01:34,059 --> 00:01:39,084
x which is frontage, times depth.

46
00:01:40,043 --> 00:01:42,004
This is a multiplication symbol.

47
00:01:42,037 --> 00:01:43,098
It's a frontage x depth because

48
00:01:44,032 --> 00:01:45,064
this is the land area

49
00:01:46,009 --> 00:01:47,065
that I own and I might

50
00:01:47,093 --> 00:01:49,042
then select my hypothesis

51
00:01:50,070 --> 00:01:53,004
as that using just

52
00:01:53,034 --> 00:01:54,059
one feature which is my

53
00:01:54,076 --> 00:01:57,043
land area, right?

54
00:01:57,057 --> 00:01:58,076
Because the area of a

55
00:01:58,093 --> 00:02:00,015
rectangle is you know,

56
00:02:00,031 --> 00:02:01,017
the product of the length

57
00:02:01,045 --> 00:02:03,035
of the size So, depending

58
00:02:03,076 --> 00:02:04,093
on what insight you might have

59
00:02:05,028 --> 00:02:07,025
into a particular problem, rather than

60
00:02:07,048 --> 00:02:08,065
just taking the features [xx]

61
00:02:09,062 --> 00:02:10,078
that we happen to have started

62
00:02:11,012 --> 00:02:12,091
off with, sometimes by defining

63
00:02:13,046 --> 00:02:15,093
new features you might actually get a better model.

64
00:02:16,078 --> 00:02:18,003
Closely related to the

65
00:02:18,015 --> 00:02:19,053
idea of choosing your features

66
00:02:19,065 --> 00:02:22,005
is this idea called polynomial regression.

67
00:02:23,000 --> 00:02:25,096
Let's say you have a housing price data set that looks like this.

68
00:02:26,087 --> 00:02:29,040
Then there are a few different models you might fit to this.

69
00:02:29,065 --> 00:02:32,031
One thing you could do is fit a quadratic model like this.

70
00:02:32,059 --> 00:02:34,086
It doesn't look like a straight line fits this data very well.

71
00:02:35,058 --> 00:02:36,044
So maybe you want to fit

72
00:02:36,075 --> 00:02:38,009
a quadratic model like this

73
00:02:38,041 --> 00:02:40,011
where you think the size, where

74
00:02:40,024 --> 00:02:41,074
you think the price is a quadratic

75
00:02:42,002 --> 00:02:43,071
function and maybe that'll

76
00:02:43,096 --> 00:02:44,090
give you, you know, a fit

77
00:02:45,002 --> 00:02:47,006
to the data that looks like that.

78
00:02:47,028 --> 00:02:48,036
But then you may decide that your

79
00:02:48,056 --> 00:02:49,068
quadratic model doesn't make sense

80
00:02:50,000 --> 00:02:51,068
because of a quadratic function, eventually

81
00:02:52,056 --> 00:02:53,055
this function comes back down

82
00:02:53,084 --> 00:02:55,036
and well, we don't think housing

83
00:02:55,059 --> 00:02:57,093
prices should go down when the size goes up too high.

84
00:02:58,096 --> 00:03:00,008
So then maybe we might

85
00:03:00,065 --> 00:03:02,009
choose a different polynomial model

86
00:03:02,068 --> 00:03:04,012
and choose to use instead a

87
00:03:04,028 --> 00:03:07,028
cubic function, and where

88
00:03:07,047 --> 00:03:08,063
we have now a third-order term

89
00:03:09,021 --> 00:03:10,040
and we fit that, maybe

90
00:03:10,080 --> 00:03:12,028
we get this sort of

91
00:03:12,038 --> 00:03:13,062
model, and maybe the

92
00:03:13,090 --> 00:03:14,096
green line is a somewhat better fit

93
00:03:15,021 --> 00:03:17,038
to the data cause it doesn't eventually come back down.

94
00:03:18,005 --> 00:03:20,093
So how do we actually fit a model like this to our data?

95
00:03:22,002 --> 00:03:23,056
Using the machinery of multivariant

96
00:03:23,068 --> 00:03:26,049
linear regression, we can

97
00:03:26,097 --> 00:03:29,083
do this with a pretty simple modification to our algorithm.

98
00:03:30,068 --> 00:03:32,016
The form of the hypothesis we,

99
00:03:32,062 --> 00:03:33,053
we know how the fit

100
00:03:34,018 --> 00:03:35,012
looks like this, where we say

101
00:03:35,077 --> 00:03:37,015
H of x is theta zero

102
00:03:37,061 --> 00:03:40,030
plus theta one x one plus x two theta X3.

103
00:03:41,055 --> 00:03:42,056
And if we want to

104
00:03:42,068 --> 00:03:45,002
fit this cubic model that

105
00:03:45,025 --> 00:03:46,066
I have boxed in green,

106
00:03:47,019 --> 00:03:48,053
what we're saying is that

107
00:03:48,093 --> 00:03:49,063
to predict the price of a

108
00:03:49,081 --> 00:03:51,000
house, it's theta 0 plus theta

109
00:03:51,034 --> 00:03:52,040
1 times the size of the house

110
00:03:53,000 --> 00:03:55,031
plus theta 2 times the square size of the house.

111
00:03:55,090 --> 00:03:58,041
So this term is equal to that term.

112
00:03:58,096 --> 00:04:00,046
And then plus theta 3

113
00:04:00,088 --> 00:04:02,021
times the cube of the

114
00:04:02,034 --> 00:04:04,003
size of the house raises that third term.

115
00:04:05,046 --> 00:04:06,068
In order to map these

116
00:04:06,099 --> 00:04:08,012
two definitions to each other,

117
00:04:08,068 --> 00:04:10,016
well, the natural way

118
00:04:10,031 --> 00:04:11,081
to do that is to set

119
00:04:12,015 --> 00:04:13,043
the first feature x one to

120
00:04:13,053 --> 00:04:15,012
be the size of the house, and

121
00:04:15,031 --> 00:04:16,049
set the second feature x two

122
00:04:16,068 --> 00:04:17,051
to be the square of the size

123
00:04:17,073 --> 00:04:20,019
of the house, and set the third feature x three to

124
00:04:20,033 --> 00:04:21,077
be the cube of the size of the house.

125
00:04:22,080 --> 00:04:24,002
And, just by choosing my

126
00:04:24,027 --> 00:04:26,007
three features this way and

127
00:04:26,030 --> 00:04:27,072
applying the machinery of linear

128
00:04:27,072 --> 00:04:30,013
regression, I can fit this

129
00:04:30,048 --> 00:04:31,067
model and end up with

130
00:04:31,088 --> 00:04:33,062
a cubic fit to my data.

131
00:04:34,036 --> 00:04:35,019
I just want to point out one

132
00:04:35,041 --> 00:04:36,043
more thing, which is that

133
00:04:36,080 --> 00:04:38,000
if you choose your features

134
00:04:38,048 --> 00:04:40,033
like this, then feature scaling

135
00:04:40,083 --> 00:04:41,094
becomes increasingly important.

136
00:04:44,012 --> 00:04:45,010
So if the size of the

137
00:04:45,016 --> 00:04:46,043
house ranges from one to

138
00:04:46,080 --> 00:04:47,073
a thousand, so, you know,

139
00:04:47,089 --> 00:04:48,089
from one to a thousand square

140
00:04:49,031 --> 00:04:50,061
feet, say, then the size

141
00:04:50,093 --> 00:04:51,095
squared of the house will

142
00:04:52,016 --> 00:04:54,035
range from one to one

143
00:04:54,051 --> 00:04:55,082
million, the square of

144
00:04:55,093 --> 00:04:58,012
a thousand, and your third

145
00:04:58,049 --> 00:05:00,072
feature x cubed, excuse me

146
00:05:01,036 --> 00:05:02,086
you, your third feature x

147
00:05:03,012 --> 00:05:04,024
three, which is the size

148
00:05:04,070 --> 00:05:05,070
cubed of the house, will range

149
00:05:05,094 --> 00:05:07,033
from one two ten to

150
00:05:07,043 --> 00:05:09,007
the nine, and so these

151
00:05:09,032 --> 00:05:10,054
three features take on very

152
00:05:10,086 --> 00:05:12,088
different ranges of values, and

153
00:05:13,049 --> 00:05:14,068
it's important to apply feature

154
00:05:15,011 --> 00:05:16,013
scaling if you're using gradient

155
00:05:16,048 --> 00:05:17,080
descent to get them into

156
00:05:18,052 --> 00:05:20,037
comparable ranges of values.

157
00:05:21,013 --> 00:05:22,051
Finally, here's one last example

158
00:05:23,025 --> 00:05:24,062
of how you really have

159
00:05:25,014 --> 00:05:27,061
broad choices in the features you use.

160
00:05:29,008 --> 00:05:30,019
Earlier we talked about how a

161
00:05:30,043 --> 00:05:31,038
quadratic model like this might

162
00:05:31,051 --> 00:05:32,086
not be ideal because, you know,

163
00:05:33,005 --> 00:05:34,030
maybe a quadratic model fits the

164
00:05:34,037 --> 00:05:35,045
data okay, but the quadratic

165
00:05:35,093 --> 00:05:37,016
function goes back down

166
00:05:37,048 --> 00:05:38,068
and we really don't want, right,

167
00:05:39,006 --> 00:05:39,086
housing prices that go down,

168
00:05:40,032 --> 00:05:42,049
to predict that, as the size of housing freezes.

169
00:05:43,056 --> 00:05:45,027
But rather than going to

170
00:05:45,036 --> 00:05:46,080
a cubic model there, you

171
00:05:46,089 --> 00:05:48,022
have, maybe, other choices of

172
00:05:48,027 --> 00:05:49,086
features and there are many possible choices.

173
00:05:50,080 --> 00:05:51,099
But just to give you another

174
00:05:52,030 --> 00:05:53,045
example of a reasonable

175
00:05:53,068 --> 00:05:55,022
choice, another reasonable choice

176
00:05:55,061 --> 00:05:56,074
might be to say that the

177
00:05:57,025 --> 00:05:58,054
price of a house is theta

178
00:05:58,085 --> 00:05:59,069
zero plus theta one times

179
00:05:59,099 --> 00:06:01,011
the size, and then plus theta

180
00:06:01,031 --> 00:06:03,043
two times the square root of the size, right?

181
00:06:03,062 --> 00:06:05,020
So the square root function is

182
00:06:05,036 --> 00:06:07,031
this sort of function, and maybe

183
00:06:08,007 --> 00:06:09,018
there will be some value of theta

184
00:06:09,030 --> 00:06:11,017
one, theta two, theta three, that

185
00:06:11,031 --> 00:06:12,068
will let you take this model

186
00:06:14,007 --> 00:06:15,025
and, for the curve that looks

187
00:06:15,043 --> 00:06:16,049
like that, and, you know,

188
00:06:16,092 --> 00:06:18,069
goes up, but sort of flattens

189
00:06:19,051 --> 00:06:21,036
out a bit and doesn't ever

190
00:06:21,054 --> 00:06:23,039
come back down.

191
00:06:24,032 --> 00:06:26,043
And, so, by having insight into, in

192
00:06:26,056 --> 00:06:27,043
this case, the shape of a

193
00:06:27,058 --> 00:06:30,029
square root function, and, into

194
00:06:30,099 --> 00:06:32,017
the shape of the data, by choosing

195
00:06:32,055 --> 00:06:34,075
different features, you can sometimes get better models.

196
00:06:37,030 --> 00:06:39,066
In this video, we talked about polynomial regression.

197
00:06:40,037 --> 00:06:41,039
That is, how to fit a

198
00:06:41,077 --> 00:06:42,094
polynomial, like a quadratic function,

199
00:06:43,036 --> 00:06:44,062
or a cubic function, to your data.

200
00:06:45,036 --> 00:06:46,025
Was also throw out this idea,

201
00:06:46,042 --> 00:06:47,039
that you have a choice in what

202
00:06:47,063 --> 00:06:48,063
features to use, such as

203
00:06:48,081 --> 00:06:49,087
that instead of using

204
00:06:50,025 --> 00:06:51,018
the frontish and the depth

205
00:06:51,054 --> 00:06:52,042
of the house, maybe, you can

206
00:06:52,060 --> 00:06:54,023
multiply them together to get

207
00:06:54,041 --> 00:06:56,076
a feature that captures the land area of a house.

208
00:06:57,083 --> 00:06:58,093
In case this seems a little

209
00:06:59,012 --> 00:07:00,087
bit bewildering, that with all

210
00:07:01,005 --> 00:07:03,087
these different feature choices, so how do I decide what features to use.

211
00:07:04,068 --> 00:07:05,056
Later in this class, we'll talk

212
00:07:05,083 --> 00:07:07,044
about some algorithms were automatically

213
00:07:07,095 --> 00:07:09,014
choosing what features are used,

214
00:07:09,036 --> 00:07:10,054
so you can have an

215
00:07:10,062 --> 00:07:11,039
algorithm look at the data

216
00:07:11,098 --> 00:07:13,037
and automatically choose for you

217
00:07:13,083 --> 00:07:14,064
whether you want to fit a

218
00:07:14,087 --> 00:07:16,081
quadratic function, or a cubic function, or something else.

219
00:07:17,081 --> 00:07:18,073
But, until we get to

220
00:07:18,081 --> 00:07:20,020
those algorithms now I just

221
00:07:20,041 --> 00:07:21,038
want you to be aware that

222
00:07:21,070 --> 00:07:22,094
you have a choice in

223
00:07:23,008 --> 00:07:24,051
what features to use, and

224
00:07:24,074 --> 00:07:26,013
by designing different features

225
00:07:26,061 --> 00:07:27,077
you can fit more complex functions

226
00:07:28,018 --> 00:07:29,052
your data then just fitting a

227
00:07:29,070 --> 00:07:31,023
straight line to the data and

228
00:07:31,083 --> 00:07:32,081
in particular you can put polynomial

229
00:07:33,039 --> 00:07:35,012
functions as well and sometimes

230
00:07:35,087 --> 00:07:37,010
by appropriate insight into the

231
00:07:37,041 --> 00:07:38,048
feature simply get a much

232
00:07:38,061 --> 00:07:40,001
better model for your data.
