
1
00:00:00,028 --> 00:00:02,091
In this video, I'd like to tell you about the idea of vectorization.

2
00:00:04,048 --> 00:00:05,083
So, whether you're using Octave

3
00:00:06,044 --> 00:00:07,079
or a similar language like MATLAB

4
00:00:08,025 --> 00:00:09,025
or whether you're using Python

5
00:00:09,058 --> 00:00:10,092
and NumPy or Java CC++.

6
00:00:12,050 --> 00:00:14,044
All of these languages have either

7
00:00:14,078 --> 00:00:16,019
built into them or have

8
00:00:16,071 --> 00:00:18,087
readily and easily accessible, different

9
00:00:19,042 --> 00:00:20,096
numerical linear algebra libraries.

10
00:00:21,082 --> 00:00:22,094
They're usually very well written,

11
00:00:23,026 --> 00:00:25,051
highly optimized, often so that developed by

12
00:00:25,066 --> 00:00:28,055
people that, you know, have PhDs in numerical computing or

13
00:00:29,017 --> 00:00:30,069
they are really specializing numerical computing.

14
00:00:32,004 --> 00:00:33,059
And when you're implementing machine

15
00:00:33,096 --> 00:00:35,054
learning algorithms, if you're able

16
00:00:35,092 --> 00:00:37,032
to take advantage of these

17
00:00:37,081 --> 00:00:39,004
linear algebra libraries or these

18
00:00:39,031 --> 00:00:41,039
numerical linear algebra libraries and

19
00:00:41,061 --> 00:00:42,090
mix the routine calls to them

20
00:00:43,036 --> 00:00:44,090
rather than sort of right call

21
00:00:45,017 --> 00:00:47,046
yourself to do things that these libraries could be doing.

22
00:00:48,003 --> 00:00:49,011
If you do that then

23
00:00:49,056 --> 00:00:51,038
often you get that "first is more efficient".

24
00:00:51,088 --> 00:00:53,000
So, just run more quickly and

25
00:00:53,013 --> 00:00:54,025
take better advantage of

26
00:00:54,086 --> 00:00:56,020
any parallel hardware your computer

27
00:00:56,061 --> 00:00:58,010
may have and so on.

28
00:00:58,027 --> 00:00:59,081
And second, it also means

29
00:01:00,053 --> 00:01:02,085
that you end up with less code that you need to write.

30
00:01:03,004 --> 00:01:04,029
So have a simpler implementation

31
00:01:04,093 --> 00:01:07,043
that is, therefore, maybe also more likely to be bug free.

32
00:01:08,054 --> 00:01:09,057
And as a concrete example.

33
00:01:10,056 --> 00:01:12,048
Rather than writing code

34
00:01:12,071 --> 00:01:14,082
yourself to multiply matrices, if

35
00:01:14,095 --> 00:01:16,009
you let Octave do it by

36
00:01:16,025 --> 00:01:17,053
typing a times b,

37
00:01:18,014 --> 00:01:19,031
that will use a very efficient

38
00:01:19,081 --> 00:01:21,040
routine to multiply the 2 matrices.

39
00:01:22,034 --> 00:01:23,037
And there's a bunch of examples like

40
00:01:24,001 --> 00:01:26,042
these where you use appropriate vectorized implementations.

41
00:01:27,018 --> 00:01:29,040
You get much simpler code, and much more efficient code.

42
00:01:30,028 --> 00:01:30,084
Let's look at some examples.

43
00:01:33,004 --> 00:01:34,085
Here's a usual hypothesis of linear

44
00:01:34,090 --> 00:01:36,023
regression and if you

45
00:01:36,034 --> 00:01:37,023
want to compute H of

46
00:01:37,031 --> 00:01:39,054
X, notice that there is a sum on the right.

47
00:01:40,001 --> 00:01:40,093
And so one thing you could

48
00:01:41,009 --> 00:01:42,056
do is compute the sum

49
00:01:42,076 --> 00:01:45,018
from J equals 0 to J equals N yourself.

50
00:01:46,062 --> 00:01:47,059
Another way to think of this

51
00:01:48,000 --> 00:01:49,001
is to think of h

52
00:01:49,020 --> 00:01:51,085
of x as theta transpose x

53
00:01:52,000 --> 00:01:53,000
and what you can do is

54
00:01:53,023 --> 00:01:55,029
think of this as you know, computing this

55
00:01:55,065 --> 00:01:57,009
in a product between 2 vectors

56
00:01:57,084 --> 00:01:59,095
where theta is, you know, your

57
00:02:00,009 --> 00:02:01,062
vector say theta 0, theta 1,

58
00:02:01,079 --> 00:02:04,034
theta 2 if you have 2 features.

59
00:02:04,081 --> 00:02:06,040
If n equals 2 and if

60
00:02:06,045 --> 00:02:07,081
you think of x as this

61
00:02:08,011 --> 00:02:11,081
vector, x0, x1, x2

62
00:02:13,012 --> 00:02:14,028
and these 2 views can

63
00:02:14,050 --> 00:02:15,096
give you 2 different implementations.

64
00:02:17,056 --> 00:02:18,013
Here's what I mean.

65
00:02:18,078 --> 00:02:20,091
Here's an unvectorized implementation for

66
00:02:21,003 --> 00:02:22,030
how to compute h of

67
00:02:22,040 --> 00:02:24,071
x and by unvectorized I mean, without vectorization.

68
00:02:26,012 --> 00:02:29,031
We might first initialize, you know, prediction to be 0.0.

69
00:02:29,046 --> 00:02:32,006
This is going to eventually, the

70
00:02:32,034 --> 00:02:33,061
prediction is going to be

71
00:02:34,030 --> 00:02:35,088
h of x and then

72
00:02:36,005 --> 00:02:37,015
I'm going to have a for loop for

73
00:02:37,027 --> 00:02:38,019
j equals one through n+1

74
00:02:38,034 --> 00:02:40,009
prediction gets incremented by

75
00:02:40,077 --> 00:02:41,072
theta j times xj.

76
00:02:41,077 --> 00:02:43,065
So, it's kind of this expression over here.

77
00:02:44,069 --> 00:02:46,090
By the way, I should mention in these

78
00:02:47,019 --> 00:02:48,074
vectors right over here, I

79
00:02:48,090 --> 00:02:50,063
had these vectors being 0 index.

80
00:02:51,011 --> 00:02:52,019
So, I had theta 0 theta 1,

81
00:02:52,056 --> 00:02:53,099
theta 2, but because MATLAB

82
00:02:54,030 --> 00:02:56,059
is one index, theta 0

83
00:02:56,066 --> 00:02:57,084
in MATLAB, we might

84
00:02:57,099 --> 00:02:59,084
end up representing as theta

85
00:03:00,018 --> 00:03:01,094
1 and this second element

86
00:03:02,003 --> 00:03:03,072
ends up as theta

87
00:03:04,038 --> 00:03:05,056
2 and this third element

88
00:03:05,087 --> 00:03:07,071
may end up as theta

89
00:03:07,099 --> 00:03:09,086
3 just because vectors in

90
00:03:09,096 --> 00:03:11,028
MATLAB are indexed starting

91
00:03:11,096 --> 00:03:13,034
from 1 even though our real

92
00:03:13,052 --> 00:03:14,078
theta and x here starting,

93
00:03:15,044 --> 00:03:16,074
indexing from 0, which

94
00:03:17,000 --> 00:03:18,016
is why here I have a for loop

95
00:03:18,075 --> 00:03:19,096
j goes from 1 through n+1

96
00:03:20,049 --> 00:03:21,084
rather than j go through

97
00:03:22,015 --> 00:03:25,031
0 up to n, right? But

98
00:03:26,030 --> 00:03:27,046
so, this is an

99
00:03:27,078 --> 00:03:29,034
unvectorized implementation in that we

100
00:03:29,050 --> 00:03:31,005
have a for loop that summing up

101
00:03:31,034 --> 00:03:32,068
the n elements of the sum.

102
00:03:34,005 --> 00:03:35,040
In contrast, here's how you

103
00:03:35,062 --> 00:03:38,019
write a vectorized implementation which

104
00:03:38,040 --> 00:03:39,059
is that you would think

105
00:03:39,093 --> 00:03:41,090
of x and theta

106
00:03:42,056 --> 00:03:43,077
as vectors, and you just set

107
00:03:43,094 --> 00:03:45,027
prediction equals theta transpose

108
00:03:46,002 --> 00:03:47,046
times x. You're just computing like so.

109
00:03:48,036 --> 00:03:50,078
Instead of writing all these

110
00:03:50,099 --> 00:03:52,031
lines of code with the for loop,

111
00:03:52,090 --> 00:03:53,097
you instead have one line

112
00:03:54,019 --> 00:03:56,013
of code and what this

113
00:03:56,062 --> 00:03:57,037
line of code on the right

114
00:03:57,053 --> 00:03:58,056
will do is it use

115
00:03:59,018 --> 00:04:01,006
Octaves highly optimized numerical

116
00:04:01,084 --> 00:04:03,028
linear algebra routines to compute

117
00:04:03,080 --> 00:04:06,003
this inner product between the

118
00:04:06,022 --> 00:04:07,074
two vectors, theta and X.
And not

119
00:04:08,018 --> 00:04:09,031
only is the vectorized implementation

120
00:04:10,018 --> 00:04:12,071
simpler, it will also run more efficiently.

121
00:04:15,081 --> 00:04:17,032
So, that was Octave, but

122
00:04:17,077 --> 00:04:19,064
issue of vectorization applies to

123
00:04:19,092 --> 00:04:21,022
other programming languages as well.

124
00:04:22,004 --> 00:04:23,047
Let's look at an example in C++.

125
00:04:24,093 --> 00:04:27,057
Here's what an unvectorized implementation might look like.

126
00:04:27,091 --> 00:04:30,057
We again initialize prediction, you know, to

127
00:04:31,033 --> 00:04:32,018
0.0 and then we now have a full

128
00:04:32,048 --> 00:04:33,039
loop for J0 up to

129
00:04:34,050 --> 00:04:36,044
n.  Prediction + equals

130
00:04:36,082 --> 00:04:38,010
theta j times x j where

131
00:04:38,056 --> 00:04:41,030
again, you have this x + for loop that you write yourself.

132
00:04:42,075 --> 00:04:44,012
In contrast, using a good

133
00:04:44,085 --> 00:04:46,036
numerical linear algebra library in

134
00:04:46,047 --> 00:04:48,037
C++, you could use

135
00:04:48,099 --> 00:04:54,043
write the function like or rather.

136
00:04:54,056 --> 00:04:56,000
In contrast, using a good

137
00:04:56,045 --> 00:04:58,006
numerical linear algebra library in

138
00:04:58,013 --> 00:04:59,083
C++, you can instead

139
00:05:00,068 --> 00:05:02,006
write code that might look like this.

140
00:05:02,045 --> 00:05:03,037
So, depending on the details

141
00:05:03,094 --> 00:05:05,018
of your numerical linear algebra

142
00:05:05,052 --> 00:05:06,079
library, you might be

143
00:05:06,082 --> 00:05:08,018
able to have an object that

144
00:05:08,057 --> 00:05:09,077
is a C++ object which is

145
00:05:09,089 --> 00:05:10,099
vector theta and a C++

146
00:05:11,035 --> 00:05:12,099
object which is a vector X,

147
00:05:13,042 --> 00:05:15,025
and you just take theta dot

148
00:05:15,050 --> 00:05:17,050
transpose times x where

149
00:05:18,012 --> 00:05:19,062
this times becomes C++ to

150
00:05:20,006 --> 00:05:21,068
overload the operator so

151
00:05:21,097 --> 00:05:25,031
that you can just multiply these two vectors in C++.

152
00:05:26,013 --> 00:05:27,045
And depending on, you know,  the details

153
00:05:28,011 --> 00:05:29,012
of your numerical and linear algebra

154
00:05:29,047 --> 00:05:30,063
library, you might end

155
00:05:30,081 --> 00:05:31,074
up using a slightly different and

156
00:05:31,083 --> 00:05:32,099
syntax, but by relying

157
00:05:33,062 --> 00:05:35,001
on a library to do this in a product.

158
00:05:35,075 --> 00:05:36,070
You can get a much simpler piece

159
00:05:36,093 --> 00:05:39,010
of code and a much more efficient one.

160
00:05:40,057 --> 00:05:42,049
Let's now look at a more sophisticated example.

161
00:05:43,057 --> 00:05:44,080
Just to remind you here's our

162
00:05:44,097 --> 00:05:46,032
update rule for gradient descent

163
00:05:46,073 --> 00:05:48,043
for linear regression and so,

164
00:05:48,077 --> 00:05:50,018
we update theta j using this

165
00:05:50,038 --> 00:05:52,081
rule for all values of J equals 0, 1, 2, and so on.

166
00:05:53,066 --> 00:05:56,008
And if I just write

167
00:05:56,025 --> 00:05:57,095
out these equations for

168
00:05:58,016 --> 00:05:59,054
theta 0 Theta one, theta two.

169
00:06:00,002 --> 00:06:01,064
Assuming we have two features.

170
00:06:02,014 --> 00:06:03,010
So N equals 2.

171
00:06:03,041 --> 00:06:04,052
Then these are the updates we

172
00:06:04,061 --> 00:06:06,044
perform to theta zero, theta one, theta two.

173
00:06:07,041 --> 00:06:08,072
where you might remember my

174
00:06:08,093 --> 00:06:10,000
saying in an earlier video

175
00:06:10,081 --> 00:06:12,066
that these should be simultaneous updates.

176
00:06:14,075 --> 00:06:16,012
So let's see if

177
00:06:16,020 --> 00:06:17,033
we can come up with a

178
00:06:17,068 --> 00:06:19,019
vectorized implementation of this.

179
00:06:20,074 --> 00:06:22,029
Here are my same 3 equations written

180
00:06:22,057 --> 00:06:24,008
on a slightly smaller font and you

181
00:06:24,017 --> 00:06:25,024
can imagine that 1 wait

182
00:06:25,051 --> 00:06:26,047
to implement this three lines

183
00:06:26,072 --> 00:06:27,068
of code is to have a

184
00:06:27,075 --> 00:06:28,082
for loop that says, you

185
00:06:28,093 --> 00:06:31,038
know, for j equals 0,

186
00:06:31,064 --> 00:06:32,092
1 through 2 the update

187
00:06:33,030 --> 00:06:35,048
theta J or something like that.

188
00:06:35,060 --> 00:06:36,056
But instead, let's come up

189
00:06:36,070 --> 00:06:40,036
with a vectorized implementation and see if we can have a simpler way.

190
00:06:40,097 --> 00:06:42,048
So, basically compress these three

191
00:06:42,075 --> 00:06:44,016
lines of code or a

192
00:06:44,030 --> 00:06:47,077
for loop that, you know, effectively does these 3 sets, 1 set at a time.

193
00:06:48,050 --> 00:06:49,037
Let's see who can these 3

194
00:06:49,066 --> 00:06:50,093
steps and compress them into

195
00:06:51,036 --> 00:06:52,091
1 line of vectorized code.

196
00:06:54,019 --> 00:06:54,062
Here's the idea.

197
00:06:55,048 --> 00:06:56,037
What I'm going to do is I'm

198
00:06:56,043 --> 00:06:58,030
going to think of theta

199
00:06:59,012 --> 00:07:00,050
as a vector and I'm

200
00:07:00,061 --> 00:07:02,025
going to update theta as theta

201
00:07:04,026 --> 00:07:07,016
minus alpha times some

202
00:07:07,045 --> 00:07:11,025
other vector, delta, where

203
00:07:12,064 --> 00:07:13,051
delta is going to be

204
00:07:13,069 --> 00:07:15,062
equal to 1 over

205
00:07:15,083 --> 00:07:17,069
m, sum from I equals

206
00:07:18,044 --> 00:07:21,092
one through m and then

207
00:07:22,018 --> 00:07:25,056
this term on the

208
00:07:25,072 --> 00:07:27,018
right, okay?

209
00:07:28,008 --> 00:07:29,058
So, let me explain what's going on here.

210
00:07:31,022 --> 00:07:32,022
Here, I'm going to treat

211
00:07:32,061 --> 00:07:34,025
theta as a vector

212
00:07:35,035 --> 00:07:37,006
so, there's an N+1 dimensional vector.

213
00:07:38,011 --> 00:07:39,066
I'm saying that theta gets, you know, updated

214
00:07:40,031 --> 00:07:42,025
as--that's the vector, our N+1.

215
00:07:43,092 --> 00:07:44,094
Alpha is a real

216
00:07:45,023 --> 00:07:46,098
number and delta

217
00:07:47,041 --> 00:07:49,050
here is a vector.

218
00:07:49,095 --> 00:07:53,054
So, this subtraction operation, that's a vector subtraction.

219
00:07:54,037 --> 00:07:54,037
Okay?

220
00:07:54,082 --> 00:07:56,030
Because alpha times delta

221
00:07:56,095 --> 00:07:58,017
is a vector and so

222
00:07:58,035 --> 00:08:00,019
I'm saying if theta gets, you know, this

223
00:08:00,036 --> 00:08:02,054
vector, alpha times delta subtracted from it.

224
00:08:04,024 --> 00:08:06,004
So, what is the vector delta?

225
00:08:06,055 --> 00:08:10,022
Well, this vector delta looks like this.

226
00:08:11,000 --> 00:08:12,000
And what this meant to

227
00:08:12,008 --> 00:08:13,020
be is really meant to be

228
00:08:14,062 --> 00:08:15,043
this thing over here.

229
00:08:17,013 --> 00:08:19,000
Concretely, delta will be

230
00:08:19,022 --> 00:08:21,077
a N+1 dimensional vector and

231
00:08:22,016 --> 00:08:23,067
the very first element of

232
00:08:23,089 --> 00:08:26,049
the vector delta is going to be equal to that.

233
00:08:27,076 --> 00:08:29,018
So, if we have

234
00:08:29,050 --> 00:08:31,014
the delta, you know, if we index it

235
00:08:31,051 --> 00:08:33,089
from 0--this is delta 0, delta 1, delta 2.

236
00:08:34,044 --> 00:08:35,090
What I want is that

237
00:08:36,055 --> 00:08:38,071
delta 0 is equal

238
00:08:39,003 --> 00:08:40,099
to, you know, this

239
00:08:41,025 --> 00:08:42,019
first box also green up

240
00:08:42,036 --> 00:08:44,086
above and indeed, you might

241
00:08:45,025 --> 00:08:46,037
be able to convince yourself that delta

242
00:08:47,009 --> 00:08:48,004
0 is this 1 of m,

243
00:08:48,062 --> 00:08:50,000
sum of, you know, h of

244
00:08:50,009 --> 00:08:52,090
x.   xi minus

245
00:08:53,039 --> 00:08:56,033
yi times xi0.

246
00:08:57,078 --> 00:08:59,061
So, let's just make

247
00:08:59,072 --> 00:09:00,090
sure that we're on the

248
00:09:00,098 --> 00:09:03,025
same page about how delta really is computed.

249
00:09:03,099 --> 00:09:04,077
Delta is one of m

250
00:09:05,044 --> 00:09:06,092
times the sum over here

251
00:09:08,027 --> 00:09:09,063
and, you know, what is this sum?

252
00:09:09,087 --> 00:09:11,017
Well, this term over

253
00:09:11,040 --> 00:09:14,089
here, that's a real number.

254
00:09:17,014 --> 00:09:19,085
And the second term over here, xi.

255
00:09:21,017 --> 00:09:23,020
This term over there is a

256
00:09:23,090 --> 00:09:25,012
vector, right? Because xi might

257
00:09:26,034 --> 00:09:26,088
be a vector.

258
00:09:26,099 --> 00:09:29,062
That would be

259
00:09:31,015 --> 00:09:33,029
xi0, xi1, xi2 right?

260
00:09:36,012 --> 00:09:37,039
And what is the summation?

261
00:09:38,020 --> 00:09:39,080
Well, what does summation say

262
00:09:40,025 --> 00:09:42,000
is that this term

263
00:09:45,063 --> 00:09:45,092
over here.

264
00:09:47,027 --> 00:09:54,016
This is equal to h+x1-y1 times

265
00:09:54,087 --> 00:09:58,035
x1 + h of

266
00:09:59,092 --> 00:10:02,047
x2-y2 times x2

267
00:10:02,075 --> 00:10:04,075
+ you know, and so on.

268
00:10:05,076 --> 00:10:05,076
Okay?

269
00:10:06,000 --> 00:10:07,022
Because this is a summation of

270
00:10:07,036 --> 00:10:08,069
the I. So, as I

271
00:10:08,096 --> 00:10:10,075
ranges from I1 through m,

272
00:10:11,034 --> 00:10:13,059
you get these different terms and you're summing up these terms.

273
00:10:15,015 --> 00:10:15,099
And the meaning of each of these

274
00:10:16,019 --> 00:10:17,060
terms is a lot like

275
00:10:18,017 --> 00:10:19,052
- if you remember actually from

276
00:10:19,074 --> 00:10:22,070
the earlier quiz in this, if you solve this equation.

277
00:10:24,011 --> 00:10:25,036
We said that in order to

278
00:10:25,050 --> 00:10:27,004
vectorize this code, we

279
00:10:27,023 --> 00:10:30,057
will instead set u2v+5w. So,

280
00:10:30,076 --> 00:10:32,015
we're saying that the vector u

281
00:10:32,037 --> 00:10:33,046
is equal to 2 times

282
00:10:33,065 --> 00:10:35,023
the vector v plus 5 times

283
00:10:35,057 --> 00:10:36,086
the vector w. So, just an

284
00:10:37,014 --> 00:10:38,070
example of how to

285
00:10:38,090 --> 00:10:42,033
add different vectors and this summation is the same thing.

286
00:10:42,044 --> 00:10:44,054
It's a saying that this

287
00:10:44,095 --> 00:10:48,032
summation over here is just some real number right?

288
00:10:49,084 --> 00:10:50,075
That's kind of like the number

289
00:10:51,000 --> 00:10:51,099
2 and some other number

290
00:10:52,087 --> 00:10:53,050
times the vector x1.

291
00:10:53,075 --> 00:10:56,070
This is like 2 times v instead

292
00:10:56,078 --> 00:10:57,089
with some other number times x1

293
00:10:59,012 --> 00:11:01,025
and then plus, you know, instead of

294
00:11:01,069 --> 00:11:03,025
5xw, we instead have some

295
00:11:03,047 --> 00:11:04,095
other real number plus some

296
00:11:05,019 --> 00:11:06,064
other vector and then you

297
00:11:06,086 --> 00:11:08,074
add on other vectors, you know,

298
00:11:08,088 --> 00:11:10,041
plus ... plus the other

299
00:11:10,053 --> 00:11:11,087
vectors, which is why

300
00:11:12,021 --> 00:11:14,087
overall, this thing

301
00:11:15,014 --> 00:11:16,079
over here, that whole

302
00:11:17,000 --> 00:11:19,052
quantity, that delta is

303
00:11:19,076 --> 00:11:22,050
just some vector, and concretely, the

304
00:11:23,067 --> 00:11:25,045
3 elements of delta correspond

305
00:11:26,029 --> 00:11:28,009
if n2, the 3 elements

306
00:11:28,082 --> 00:11:30,064
of delta correspond exactly to

307
00:11:31,050 --> 00:11:32,098
this thing to the second

308
00:11:33,033 --> 00:11:34,088
thing and this third

309
00:11:35,005 --> 00:11:36,016
thing, which is why

310
00:11:36,040 --> 00:11:38,012
when you update theta, according to

311
00:11:38,026 --> 00:11:39,080
theta minus alpha delta,

312
00:11:41,000 --> 00:11:42,075
we end up having exactly the

313
00:11:42,083 --> 00:11:44,061
same simultaneous updates as the

314
00:11:44,096 --> 00:11:46,044
update rules that we have on top.

315
00:11:47,084 --> 00:11:48,075
So, I know that there

316
00:11:48,089 --> 00:11:50,022
was a lot that happened on

317
00:11:50,050 --> 00:11:52,050
the slides, but again, feel

318
00:11:52,064 --> 00:11:54,032
free to pause the video and

319
00:11:54,050 --> 00:11:55,092
I either encourage you to

320
00:11:56,052 --> 00:11:57,097
step through the difference. If

321
00:11:58,024 --> 00:11:59,001
you're unsure of what just happen,

322
00:11:59,037 --> 00:12:01,054
I encourage you to step through

323
00:12:01,069 --> 00:12:02,074
the slide to make sure you

324
00:12:02,087 --> 00:12:04,026
understand why is it

325
00:12:04,058 --> 00:12:06,050
that this update here with

326
00:12:07,005 --> 00:12:09,030
this definition of delta, right?

327
00:12:09,075 --> 00:12:10,062
Why is it that that equal

328
00:12:10,091 --> 00:12:13,055
to this update on top and

329
00:12:13,066 --> 00:12:14,090
it's still not clear when insight is

330
00:12:15,001 --> 00:12:17,058
that, you know, this thing over here.

331
00:12:18,039 --> 00:12:20,012
That's exactly the vector

332
00:12:20,060 --> 00:12:21,094
x and so, we're

333
00:12:22,009 --> 00:12:23,004
just taking, you know, all

334
00:12:23,027 --> 00:12:24,087
3 of these computations and compressing

335
00:12:25,049 --> 00:12:26,065
them into one step

336
00:12:27,004 --> 00:12:28,084
with the this vector delta,

337
00:12:29,076 --> 00:12:31,000
which is why we can come

338
00:12:31,026 --> 00:12:33,025
up with a vectorized implementation of

339
00:12:33,049 --> 00:12:35,085
this step of linear regression this way.

340
00:12:36,094 --> 00:12:38,047
So I hope this

341
00:12:38,065 --> 00:12:40,025
step makes sense, and do

342
00:12:40,061 --> 00:12:41,055
look at the video and make

343
00:12:41,073 --> 00:12:43,009
sure and see if you can understand it.

344
00:12:43,099 --> 00:12:45,075
In case you don't understand The

345
00:12:46,003 --> 00:12:47,086
equivalence of this math if

346
00:12:48,000 --> 00:12:49,001
you implement this, this turns

347
00:12:49,039 --> 00:12:50,038
out to be the right answer anyway,

348
00:12:50,089 --> 00:12:51,087
so even if you didn't

349
00:12:52,020 --> 00:12:56,008
quite understand the equivalence, if you just implement it this way,

350
00:12:56,040 --> 00:12:58,010
you'll be able to get linear regressions to work.

351
00:12:58,096 --> 00:13:00,053
So, if you're able to

352
00:13:00,065 --> 00:13:01,076
figure out why these 2 steps

353
00:13:02,020 --> 00:13:03,083
are equivalent then hopefully that

354
00:13:04,011 --> 00:13:05,047
would give you a better understanding of vectorization

355
00:13:06,023 --> 00:13:09,009
as well, and finally,

356
00:13:10,009 --> 00:13:12,013
if you're implementing linear

357
00:13:12,037 --> 00:13:14,037
regression using more than one or two features.

358
00:13:14,086 --> 00:13:16,024
So, sometimes we use linear

359
00:13:16,054 --> 00:13:17,057
regression with tens or hundreds

360
00:13:18,007 --> 00:13:19,086
thousands of features, but if

361
00:13:19,098 --> 00:13:21,012
you use the vectorized implementation

362
00:13:21,083 --> 00:13:23,051
of linear regression, usually that

363
00:13:23,066 --> 00:13:25,041
will run much faster than if

364
00:13:25,059 --> 00:13:26,062
you had say your old

365
00:13:26,087 --> 00:13:28,003
for loop that was you

366
00:13:28,014 --> 00:13:30,066
know, updating theta 0 then theta 1 then theta 2 yourself.

367
00:13:31,050 --> 00:13:33,060
So, using a vectorized implementation, you

368
00:13:33,072 --> 00:13:34,054
should be able to get a

369
00:13:34,058 --> 00:13:36,070
much more efficient implementation of linear regression.

370
00:13:37,078 --> 00:13:39,007
And when you vectorize later

371
00:13:39,034 --> 00:13:40,023
algorithms that we'll see in

372
00:13:40,036 --> 00:13:41,039
this class is a good

373
00:13:41,050 --> 00:13:42,088
trick whether an octave

374
00:13:43,030 --> 00:13:44,028
or some of the language, the C++

375
00:13:44,075 --> 00:13:47,012
Java for getting your code to run more efficiently.
