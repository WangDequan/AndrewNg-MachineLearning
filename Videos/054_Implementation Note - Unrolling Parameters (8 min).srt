
1
00:00:00,025 --> 00:00:01,053
In the previous video, we talked

2
00:00:01,085 --> 00:00:02,087
about how to use back propagation

3
00:00:03,098 --> 00:00:05,080
to compute the derivatives of your cost function.

4
00:00:06,078 --> 00:00:07,076
In this video, I want

5
00:00:08,002 --> 00:00:10,025
to quickly tell you about one implementational detail of

6
00:00:11,022 --> 00:00:13,010
unrolling your parameters from

7
00:00:13,067 --> 00:00:15,050
matrices into vectors, which we

8
00:00:15,060 --> 00:00:17,087
need in order to use the advanced optimization routines.

9
00:00:20,023 --> 00:00:21,046
Concretely, let's say

10
00:00:21,064 --> 00:00:23,012
you've implemented a cost function

11
00:00:23,066 --> 00:00:24,087
that takes this input, you know, parameters

12
00:00:25,042 --> 00:00:28,069
theta and returns the cost function and returns derivatives.

13
00:00:30,005 --> 00:00:31,026
Then you can pass this to

14
00:00:31,051 --> 00:00:33,082
an advanced authorization algorithm by fminunc

15
00:00:34,007 --> 00:00:34,078
and fminunc

16
00:00:34,089 --> 00:00:35,089
isn't the only one by the way.

17
00:00:36,006 --> 00:00:38,065
There are also other advanced authorization algorithms.

18
00:00:39,071 --> 00:00:40,090
But what all of them

19
00:00:41,003 --> 00:00:41,096
do is take those input

20
00:00:42,072 --> 00:00:43,056
pointedly the cost function,

21
00:00:44,049 --> 00:00:45,072
and some initial value of theta.

22
00:00:47,000 --> 00:00:48,049
And both, and these

23
00:00:48,072 --> 00:00:51,060
routines assume that theta and

24
00:00:51,074 --> 00:00:53,035
the initial value of theta, that

25
00:00:53,057 --> 00:00:55,040
these are parameter vectors, maybe

26
00:00:55,064 --> 00:00:57,003
Rn or Rn plus 1.

27
00:00:57,086 --> 00:01:00,043
But these are vectors and it

28
00:01:00,053 --> 00:01:01,088
also assumes that, you know, your cost

29
00:01:02,014 --> 00:01:03,077
function will return as

30
00:01:03,096 --> 00:01:05,064
a second return value this

31
00:01:05,082 --> 00:01:07,040
gradient which is also Rn

32
00:01:07,064 --> 00:01:09,085
and Rn plus 1. So also a vector.

33
00:01:10,084 --> 00:01:11,089
This worked fine when we

34
00:01:12,004 --> 00:01:14,003
were using logistic progression but

35
00:01:14,021 --> 00:01:15,012
now that we're using a neural

36
00:01:15,028 --> 00:01:17,015
network our parameters are

37
00:01:17,021 --> 00:01:18,037
no longer vectors, but instead

38
00:01:18,098 --> 00:01:21,010
they are these matrices where for

39
00:01:21,031 --> 00:01:22,067
a full neural network we would

40
00:01:22,082 --> 00:01:26,004
have parameter matrices theta 1, theta 2, theta 3

41
00:01:26,070 --> 00:01:28,007
that we might represent in Octave

42
00:01:28,068 --> 00:01:30,065
as these matrices theta 1, theta 2, theta 3.

43
00:01:31,045 --> 00:01:33,015
And similarly these gradient

44
00:01:33,076 --> 00:01:35,003
terms that were expected to return.

45
00:01:35,071 --> 00:01:36,089
Well, in the previous video we

46
00:01:36,098 --> 00:01:38,043
showed how to compute these

47
00:01:38,084 --> 00:01:40,051
gradient matrices, which was

48
00:01:40,098 --> 00:01:42,029
capital D1, capital D2,

49
00:01:42,056 --> 00:01:43,095
capital D3, which we

50
00:01:44,007 --> 00:01:46,012
might represent an octave as matrices D1, D2, D3.

51
00:01:48,007 --> 00:01:49,015
In this video I want

52
00:01:49,048 --> 00:01:50,042
to quickly tell you about the

53
00:01:50,051 --> 00:01:51,048
idea of how to take

54
00:01:51,098 --> 00:01:54,006
these matrices and unroll them into vectors.

55
00:01:54,059 --> 00:01:55,075
So that they end up

56
00:01:55,090 --> 00:01:57,079
being in a format suitable for

57
00:01:57,093 --> 00:02:00,009
passing into as theta here off for getting

58
00:02:00,045 --> 00:02:01,084
out for a gradient there.

59
00:02:03,021 --> 00:02:04,054
Concretely, let's say we

60
00:02:04,067 --> 00:02:06,073
have a neural network with one

61
00:02:06,095 --> 00:02:08,025
input layer with ten units,

62
00:02:09,000 --> 00:02:10,000
hidden layer with ten units

63
00:02:10,053 --> 00:02:11,087
and one output layer with

64
00:02:12,002 --> 00:02:13,009
just one unit, so s1

65
00:02:13,027 --> 00:02:14,003
is the number of units in layer one

66
00:02:14,043 --> 00:02:15,071
and s2 is the

67
00:02:15,086 --> 00:02:18,021
number of units in layer two, and s3 is a number

68
00:02:18,052 --> 00:02:20,069
of units in layer three.

69
00:02:21,056 --> 00:02:23,019
In this case, the dimension of

70
00:02:23,046 --> 00:02:25,024
your matrices theta and

71
00:02:25,034 --> 00:02:26,037
D are going to be

72
00:02:26,056 --> 00:02:28,011
given by these expressions.

73
00:02:28,052 --> 00:02:30,030
For example, theta one

74
00:02:30,062 --> 00:02:33,021
is going to a 10 by 11 matrix and so on.

75
00:02:34,041 --> 00:02:35,074
So in if you want

76
00:02:35,094 --> 00:02:37,096
to convert between these matrices.

77
00:02:38,058 --> 00:02:38,058
vectors.

78
00:02:39,033 --> 00:02:40,059
What you can do is take

79
00:02:40,083 --> 00:02:42,012
your theta 1, theta

80
00:02:42,034 --> 00:02:44,021
2, theta 3, and write this

81
00:02:44,040 --> 00:02:45,046
piece of code and this will

82
00:02:45,061 --> 00:02:46,081
take all the elements of

83
00:02:46,090 --> 00:02:48,053
your three theta matrices and

84
00:02:48,077 --> 00:02:49,040
take all the elements

85
00:02:49,086 --> 00:02:51,015
of theta one, all the

86
00:02:51,025 --> 00:02:52,028
elements of theta 2, all the

87
00:02:52,040 --> 00:02:53,084
elements of theta 3,

88
00:02:54,012 --> 00:02:55,050
and unroll them and put

89
00:02:55,077 --> 00:02:57,041
all the elements into a big long vector.

90
00:02:58,053 --> 00:02:59,087
Which is thetaVec and similarly

91
00:03:00,096 --> 00:03:02,050
the second command would take

92
00:03:02,083 --> 00:03:04,034
all of your D matrices and

93
00:03:04,049 --> 00:03:05,059
unroll them into a big

94
00:03:05,093 --> 00:03:07,034
long vector and call them

95
00:03:07,050 --> 00:03:08,081
DVec.
And finally

96
00:03:09,037 --> 00:03:10,033
if you want to go back from

97
00:03:10,052 --> 00:03:13,037
the vector representations to the matrix representations.

98
00:03:14,062 --> 00:03:15,062
What you do to get back

99
00:03:15,084 --> 00:03:17,071
to theta one say is take

100
00:03:17,093 --> 00:03:19,025
thetaVec and pull

101
00:03:19,053 --> 00:03:20,097
out the first 110 elements.

102
00:03:21,046 --> 00:03:22,093
So theta 1 has 110

103
00:03:23,038 --> 00:03:24,065
elements because it's a

104
00:03:24,071 --> 00:03:26,041
10 by 11 matrix so that

105
00:03:26,081 --> 00:03:28,019
pulls out the first 110 elements

106
00:03:28,053 --> 00:03:30,019
and then you can

107
00:03:30,037 --> 00:03:32,096
use the reshape command to reshape those back into theta 1.

108
00:03:33,000 --> 00:03:34,072
And similarly, to get

109
00:03:34,090 --> 00:03:35,084
back theta 2 you pull

110
00:03:36,028 --> 00:03:39,000
out the next 110 elements and reshape it.

111
00:03:39,066 --> 00:03:41,040
And for theta 3, you pull out

112
00:03:41,044 --> 00:03:43,031
the final eleven elements and run

113
00:03:43,050 --> 00:03:45,021
reshape to get back the theta 3.

114
00:03:48,084 --> 00:03:50,069
Here's a quick Octave demo of that process.

115
00:03:51,027 --> 00:03:52,037
So for this example

116
00:03:53,000 --> 00:03:54,053
let's set theta 1 equal

117
00:03:55,034 --> 00:03:57,043
to be ones of 10 by

118
00:03:57,066 --> 00:03:59,058
11, so it's a matrix of all ones. And

119
00:04:00,036 --> 00:04:01,040
just to make this easier seen,

120
00:04:01,075 --> 00:04:03,006
let's set that to be 2

121
00:04:03,028 --> 00:04:05,015
times ones, 10 by

122
00:04:05,031 --> 00:04:07,038
11 and let's

123
00:04:07,059 --> 00:04:09,056
set theta 3 equals 3

124
00:04:10,028 --> 00:04:12,011
times 1's of 1 by 11.

125
00:04:12,038 --> 00:04:13,068
So this is 3

126
00:04:13,097 --> 00:04:17,002
separate matrices: theta 1, theta 2, theta 3.

127
00:04:17,076 --> 00:04:19,000
We want to put all of these as a vector.

128
00:04:19,067 --> 00:04:22,074
ThetaVec equals theta

129
00:04:23,037 --> 00:04:26,066
1; theta 2

130
00:04:28,054 --> 00:04:28,099
theta 3.

131
00:04:29,025 --> 00:04:32,006
Right, that's a colon

132
00:04:32,054 --> 00:04:34,022
in the middle and like so

133
00:04:35,035 --> 00:04:37,042
and now thetavec is

134
00:04:37,058 --> 00:04:40,008
going to be a very long vector.

135
00:04:41,005 --> 00:04:41,091
That's 231 elements.

136
00:04:42,097 --> 00:04:46,000
If I display it, I find

137
00:04:46,029 --> 00:04:47,063
that this very long vector with

138
00:04:47,077 --> 00:04:48,061
all the elements of the first

139
00:04:48,087 --> 00:04:49,062
matrix, all the elements of

140
00:04:50,008 --> 00:04:52,036
the second matrix, then all the elements of the third matrix.

141
00:04:53,048 --> 00:04:54,044
And if I want to get back

142
00:04:54,093 --> 00:04:56,042
my original matrices, I can

143
00:04:56,050 --> 00:05:00,004
do reshape thetaVec.

144
00:05:01,039 --> 00:05:02,057
Let's pull out the first 110

145
00:05:03,010 --> 00:05:05,063
elements and reshape them to a 10 by 11 matrix.

146
00:05:06,081 --> 00:05:08,024
This gives me back theta 1.

147
00:05:08,068 --> 00:05:09,076
And if I then pull

148
00:05:10,027 --> 00:05:12,022
out the next 110 elements.

149
00:05:12,072 --> 00:05:14,068
So that's indices 111 to 220.

150
00:05:14,085 --> 00:05:16,047
I get back all of my 2's.

151
00:05:18,002 --> 00:05:19,032
And if I go

152
00:05:20,085 --> 00:05:22,011
from 221 up to

153
00:05:22,027 --> 00:05:24,024
the last element, which is

154
00:05:24,043 --> 00:05:25,097
element 231, and reshape to

155
00:05:26,006 --> 00:05:28,012
1 by 11, I get back theta 3.

156
00:05:30,081 --> 00:05:32,011
To make this process really concrete,

157
00:05:32,094 --> 00:05:34,075
here's how we use the unrolling

158
00:05:35,031 --> 00:05:36,099
idea to implement our learning algorithm.

159
00:05:38,019 --> 00:05:39,018
Let's say that you have some

160
00:05:39,049 --> 00:05:40,060
initial value of the parameters

161
00:05:41,017 --> 00:05:42,041
theta 1, theta 2, theta 3.

162
00:05:42,094 --> 00:05:43,074
What we're going to do

163
00:05:44,001 --> 00:05:45,087
is take these and unroll

164
00:05:46,029 --> 00:05:47,061
them into a long vector

165
00:05:47,095 --> 00:05:50,037
we're gonna call initial theta to

166
00:05:50,060 --> 00:05:52,017
pass in to fminunc

167
00:05:52,036 --> 00:05:54,089
as this initial setting of the parameters theta.

168
00:05:56,016 --> 00:05:58,031
The other thing we need to do is implement the cost function.

169
00:05:59,031 --> 00:06:01,050
Here's my implementation of the cost function.

170
00:06:02,089 --> 00:06:04,006
The cost function is going to

171
00:06:04,016 --> 00:06:05,050
give us input, thetaVec,

172
00:06:05,098 --> 00:06:07,008
which is going to be all

173
00:06:07,035 --> 00:06:08,076
of my parameters vectors that in

174
00:06:08,087 --> 00:06:10,068
the form that's been unrolled into a vector.

175
00:06:11,095 --> 00:06:12,080
So the first thing I'm going to

176
00:06:13,000 --> 00:06:13,088
do is I'm going to use

177
00:06:14,010 --> 00:06:16,057
thetaVec and I'm going to use the reshape functions.

178
00:06:17,004 --> 00:06:18,012
So I'll pull out elements from

179
00:06:18,031 --> 00:06:19,043
thetaVec and use reshape

180
00:06:19,075 --> 00:06:20,094
to get back my

181
00:06:21,031 --> 00:06:23,056
original parameter matrices, theta 1, theta 2, theta 3.

182
00:06:24,012 --> 00:06:26,052
So these are going to be matrices that I'm going to get.

183
00:06:26,062 --> 00:06:28,000
So that gives me a

184
00:06:28,006 --> 00:06:29,092
more convenient form in which

185
00:06:30,012 --> 00:06:31,057
to use these matrices so that I

186
00:06:31,075 --> 00:06:33,058
can run forward propagation and

187
00:06:33,087 --> 00:06:35,039
back propagation to compute my

188
00:06:35,056 --> 00:06:38,013
derivatives, and to compute my cost function j of theta.

189
00:06:39,070 --> 00:06:40,089
And finally, I can then

190
00:06:41,012 --> 00:06:42,062
take my derivatives and unroll

191
00:06:43,002 --> 00:06:44,052
them, to keeping the elements

192
00:06:45,013 --> 00:06:47,043
in the same ordering as I did when I unroll my thetas.

193
00:06:48,038 --> 00:06:49,077
But I'm gonna unroll D1, D2,

194
00:06:50,002 --> 00:06:51,032
D3, to get gradientVec

195
00:06:52,018 --> 00:06:55,018
which is now what my cost function can return.

196
00:06:55,049 --> 00:06:57,042
It can return a vector of these derivatives.

197
00:06:59,014 --> 00:07:00,031
So, hopefully, you now have

198
00:07:00,049 --> 00:07:01,064
a good sense of how to

199
00:07:01,088 --> 00:07:03,019
convert back and forth between

200
00:07:03,036 --> 00:07:04,097
the matrix representation of the

201
00:07:05,008 --> 00:07:08,022
parameters versus the vector representation of the parameters.

202
00:07:09,036 --> 00:07:10,029
The advantage of the matrix

203
00:07:10,075 --> 00:07:12,032
representation is that when

204
00:07:12,047 --> 00:07:13,052
your parameters are stored as

205
00:07:13,067 --> 00:07:15,067
matrices it's more convenient when

206
00:07:15,082 --> 00:07:17,043
you're doing forward propagation and

207
00:07:17,052 --> 00:07:19,011
back propagation and it's easier

208
00:07:19,085 --> 00:07:21,016
when your parameters are stored as

209
00:07:21,036 --> 00:07:22,076
matrices to take advantage

210
00:07:23,039 --> 00:07:24,077
of the, sort of, vectorized implementations.

211
00:07:26,023 --> 00:07:27,089
Whereas in contrast the advantage of

212
00:07:28,008 --> 00:07:30,025
the vector representation, when you

213
00:07:30,031 --> 00:07:31,081
have like thetaVec or DVec is that

214
00:07:32,050 --> 00:07:34,054
when you are using the advanced optimization algorithms.

215
00:07:34,076 --> 00:07:36,063
Those algorithms tend to

216
00:07:36,075 --> 00:07:37,073
assume that you have

217
00:07:38,008 --> 00:07:40,073
all of your parameters unrolled into a big long vector.

218
00:07:41,072 --> 00:07:42,093
And so with what we just

219
00:07:43,013 --> 00:07:44,064
went through, hopefully you can now quickly

220
00:07:45,041 --> 00:07:47,001
convert between the two as needed.
