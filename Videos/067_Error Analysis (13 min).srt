
1
00:00:00,021 --> 00:00:01,030
In the last video, I talked

2
00:00:01,060 --> 00:00:03,039
about how when faced with

3
00:00:03,052 --> 00:00:04,078
a machine learning problem, there are

4
00:00:04,098 --> 00:00:07,025
often lots of different ideas on how to improve the algorithm.

5
00:00:08,046 --> 00:00:09,050
In this video let's

6
00:00:09,065 --> 00:00:11,006
talk about the concepts of error

7
00:00:11,033 --> 00:00:12,098
analysis which will help

8
00:00:13,007 --> 00:00:13,098
me give you a way to more

9
00:00:14,030 --> 00:00:15,083
systematically make some of these decisions.

10
00:00:18,007 --> 00:00:19,042
If you're starting work on a

11
00:00:19,053 --> 00:00:21,021
machine learning product or building

12
00:00:21,039 --> 00:00:23,033
a machine learning application, it is

13
00:00:23,048 --> 00:00:24,087
often considered very good practice

14
00:00:25,083 --> 00:00:27,000
to start, not by building

15
00:00:27,051 --> 00:00:29,007
a very complicated system with

16
00:00:29,021 --> 00:00:30,048
lots of complex features and so

17
00:00:30,092 --> 00:00:32,045
on, but to instead start

18
00:00:33,006 --> 00:00:34,011
by building a very simple

19
00:00:34,050 --> 00:00:35,075
algorithm, the you can implement quickly.

20
00:00:37,047 --> 00:00:38,060
And when I start on

21
00:00:38,074 --> 00:00:39,077
a learning problem, what I usually

22
00:00:40,014 --> 00:00:41,035
do is spend at most one

23
00:00:41,057 --> 00:00:43,015
day, literally at most 24

24
00:00:43,046 --> 00:00:46,003
hours to try to get something really quick and dirty.

25
00:00:47,003 --> 00:00:48,054
Frankly not at all sophisticated system.

26
00:00:49,036 --> 00:00:50,031
But get something really quick and

27
00:00:50,039 --> 00:00:52,007
dirty running and implement

28
00:00:52,059 --> 00:00:53,071
it and then test it on

29
00:00:53,088 --> 00:00:55,086
my cross validation data. Once

30
00:00:56,004 --> 00:00:57,014
you've done that, you can

31
00:00:57,047 --> 00:00:58,068
then plot learning curves.

32
00:00:59,096 --> 00:01:02,067
This is what we talked about in the previous set of videos.

33
00:01:03,022 --> 00:01:05,015
But plot learning curves of the

34
00:01:05,037 --> 00:01:07,012
training and test errors to

35
00:01:07,031 --> 00:01:08,028
try to figure out if your

36
00:01:08,040 --> 00:01:09,062
learning algorithm may be suffering

37
00:01:10,012 --> 00:01:11,023
from high bias or high

38
00:01:11,043 --> 00:01:13,018
variance or something else and

39
00:01:13,043 --> 00:01:14,037
use that to try to

40
00:01:14,048 --> 00:01:15,060
decide if having more data

41
00:01:16,007 --> 00:01:17,098
and more features and so on are likely to help.

42
00:01:18,067 --> 00:01:19,082
And the reason that this

43
00:01:20,000 --> 00:01:20,098
is a good approach is often

44
00:01:21,093 --> 00:01:22,098
when you're just starting out on

45
00:01:23,009 --> 00:01:24,045
a learning problem, there's really no

46
00:01:24,068 --> 00:01:25,081
way to tell in advance

47
00:01:26,048 --> 00:01:27,035
whether you need more complex

48
00:01:27,079 --> 00:01:29,020
features or whether you need

49
00:01:29,025 --> 00:01:30,095
more data or something else.

50
00:01:31,028 --> 00:01:32,026
And it's just very hard to tell

51
00:01:32,051 --> 00:01:33,084
in advance, that is in

52
00:01:33,096 --> 00:01:36,004
the absence of evidence, in

53
00:01:36,015 --> 00:01:37,084
the absence of seeing a

54
00:01:37,096 --> 00:01:39,012
learning curve, it's just incredibly

55
00:01:39,075 --> 00:01:42,085
difficult to figure out where you should be spending your time.

56
00:01:43,076 --> 00:01:45,035
And it's often by implementing even

57
00:01:45,073 --> 00:01:46,067
a very, very quick and dirty

58
00:01:46,098 --> 00:01:48,009
implementation and by plotting

59
00:01:48,054 --> 00:01:51,006
learning curves that that helps you make these decisions.

60
00:01:52,057 --> 00:01:53,034
So if you like, you can think

61
00:01:53,056 --> 00:01:54,048
of this as a way of

62
00:01:54,062 --> 00:01:56,026
avoiding what's sometimes called

63
00:01:56,056 --> 00:01:58,095
premature optimization in computer programming.

64
00:02:00,000 --> 00:02:01,006
And this is idea that just

65
00:02:01,020 --> 00:02:03,012
says that we should let

66
00:02:03,045 --> 00:02:04,092
evidence guide our decisions

67
00:02:05,065 --> 00:02:06,054
on where to spend our time

68
00:02:07,015 --> 00:02:08,015
rather than use gut feeling,

69
00:02:09,006 --> 00:02:09,068
which is often wrong.

70
00:02:10,093 --> 00:02:12,012
In addition to plotting learning

71
00:02:12,038 --> 00:02:13,053
curves, one other thing

72
00:02:13,081 --> 00:02:16,043
that's often very useful to do is what's called error analysis.

73
00:02:18,012 --> 00:02:19,008
And what I mean by that is

74
00:02:19,028 --> 00:02:20,052
that when building, say

75
00:02:20,077 --> 00:02:22,018
a spam classifier, I will

76
00:02:22,046 --> 00:02:24,050
often look at my

77
00:02:24,072 --> 00:02:26,068
cross validation set and manually

78
00:02:27,036 --> 00:02:29,011
look at the emails that my

79
00:02:29,031 --> 00:02:30,090
algorithm is making errors on.

80
00:02:31,018 --> 00:02:32,025
So, look at the spam emails

81
00:02:32,062 --> 00:02:34,043
and non-spam emails that the

82
00:02:34,063 --> 00:02:36,091
algorithm is misclassifying, and see

83
00:02:37,043 --> 00:02:38,059
if you can spot any systematic

84
00:02:39,021 --> 00:02:41,030
patterns in what type of examples it is misclassifying.

85
00:02:42,097 --> 00:02:44,056
And often by doing that, this

86
00:02:44,081 --> 00:02:45,096
is the process that would inspire

87
00:02:47,016 --> 00:02:48,080
you to design new features.

88
00:02:49,043 --> 00:02:50,041
Or they'll tell you whether the

89
00:02:50,091 --> 00:02:52,015
current things or current

90
00:02:52,040 --> 00:02:53,028
shortcomings of the system

91
00:02:54,027 --> 00:02:55,055
and give you the inspiration you

92
00:02:55,065 --> 00:02:57,068
need to come up with improvements to it.

93
00:02:58,025 --> 00:03:00,006
Concretely, here's a specific example.

94
00:03:01,034 --> 00:03:02,036
Let's say you've built a spam

95
00:03:02,078 --> 00:03:05,074
classifier and you

96
00:03:05,084 --> 00:03:07,071
have 500 examples in

97
00:03:07,093 --> 00:03:09,065
your cross-validation set.

98
00:03:10,040 --> 00:03:11,075
And let's say in this example, that the

99
00:03:12,000 --> 00:03:13,006
algorithm has a very high error

100
00:03:13,034 --> 00:03:14,063
rate, and it misclassifies a

101
00:03:14,090 --> 00:03:16,050
hundred of these cross-validation examples.

102
00:03:18,077 --> 00:03:19,084
So what I do is manually

103
00:03:20,044 --> 00:03:22,037
examine these 100 errors, and

104
00:03:22,053 --> 00:03:24,044
manually categorize them, based

105
00:03:24,069 --> 00:03:25,081
on things like what type

106
00:03:25,097 --> 00:03:27,011
of email it is and

107
00:03:27,027 --> 00:03:28,062
what cues or what features you

108
00:03:28,071 --> 00:03:31,012
think might have helped the algorithm classify them incorrectly.

109
00:03:32,044 --> 00:03:33,087
So, specifically, by what

110
00:03:34,008 --> 00:03:35,005
type of email it is,

111
00:03:35,056 --> 00:03:36,087
you know, if I look through these

112
00:03:37,013 --> 00:03:38,018
hundred errors I may find

113
00:03:38,052 --> 00:03:39,065
that maybe the most

114
00:03:39,096 --> 00:03:41,034
common types of spam

115
00:03:41,084 --> 00:03:43,044
emails in misclassifies are maybe

116
00:03:44,000 --> 00:03:45,061
emails on pharmacy, so basically

117
00:03:45,061 --> 00:03:48,030
these are emails trying to

118
00:03:48,061 --> 00:03:50,000
sell drugs, maybe emails that are

119
00:03:50,018 --> 00:03:51,074
trying to sell replicas -

120
00:03:51,075 --> 00:03:54,033
those are those fake watches fake you know, random things.

121
00:03:56,015 --> 00:03:59,040
Maybe have some emails trying to steal passwords.

122
00:04:00,024 --> 00:04:01,040
These are also called phishing emails.

123
00:04:02,018 --> 00:04:04,068
But that's another big category of emails and maybe other categories.

124
00:04:06,015 --> 00:04:07,080
So, in terms

125
00:04:08,012 --> 00:04:09,022
of classify what type of email

126
00:04:09,053 --> 00:04:10,041
it is, I would actually go through

127
00:04:10,088 --> 00:04:11,099
and count up, you know, of

128
00:04:12,019 --> 00:04:14,021
my 100 emails, maybe I

129
00:04:14,040 --> 00:04:15,050
find that twelve of the

130
00:04:15,062 --> 00:04:17,060
mislabeled emails are pharma emails.

131
00:04:18,010 --> 00:04:19,045
And maybe four of them

132
00:04:19,069 --> 00:04:20,083
are emails trying to sell

133
00:04:20,098 --> 00:04:22,068
replicas, they sell fake watches or something.

134
00:04:23,072 --> 00:04:25,006
And maybe I find that 53

135
00:04:25,064 --> 00:04:26,097
of them are these,

136
00:04:27,072 --> 00:04:29,048
what's called phishing emails, basically emails

137
00:04:29,073 --> 00:04:30,089
trying to persuade you to

138
00:04:31,001 --> 00:04:32,075
give them your password, and 31 emails are other types of emails.

139
00:04:35,032 --> 00:04:37,020
And it's by counting up the

140
00:04:37,027 --> 00:04:38,027
number of emails in these

141
00:04:38,043 --> 00:04:39,054
different categories that you might

142
00:04:39,079 --> 00:04:41,056
discover, for example, that the

143
00:04:41,087 --> 00:04:43,010
algorithm is doing really particularly

144
00:04:44,017 --> 00:04:45,063
poorly on emails trying to

145
00:04:45,077 --> 00:04:47,024
steal passwords, and that

146
00:04:47,039 --> 00:04:49,023
may suggest that it might

147
00:04:49,037 --> 00:04:50,049
be worth your effort to look

148
00:04:50,068 --> 00:04:51,064
more carefully at that type

149
00:04:51,089 --> 00:04:53,035
of email, and see if

150
00:04:53,044 --> 00:04:54,044
you can come up with better features

151
00:04:55,006 --> 00:04:56,027
to categorize them correctly.

152
00:04:57,055 --> 00:04:58,093
And also, what I might

153
00:04:59,000 --> 00:05:00,012
do is look at what cues,

154
00:05:00,055 --> 00:05:02,012
or what features, additional features

155
00:05:02,062 --> 00:05:04,092
might have helped the algorithm classify the emails.

156
00:05:06,008 --> 00:05:06,097
So let's say that some of

157
00:05:07,006 --> 00:05:09,069
our hypotheses about things or

158
00:05:09,083 --> 00:05:10,077
features that might help us

159
00:05:10,092 --> 00:05:13,024
classify emails better are trying

160
00:05:13,049 --> 00:05:15,060
to detect deliberate misspellings versus

161
00:05:16,022 --> 00:05:18,061
unusual email routing versus unusual, you know,

162
00:05:19,094 --> 00:05:21,044
spamming punctuation, such as

163
00:05:21,079 --> 00:05:23,023
people use a lot of exclamation marks.

164
00:05:23,069 --> 00:05:24,047
And once again, I would manually

165
00:05:24,086 --> 00:05:25,067
go through and let's say

166
00:05:25,075 --> 00:05:27,049
I find five cases of

167
00:05:27,062 --> 00:05:29,039
this, and 16 of

168
00:05:29,050 --> 00:05:30,056
this, and 32 of this and

169
00:05:31,018 --> 00:05:33,062
a bunch of other types of emails as well.

170
00:05:34,076 --> 00:05:36,018
And if this is what

171
00:05:36,035 --> 00:05:37,047
you get on your cross validation

172
00:05:38,006 --> 00:05:39,017
set then it really tells

173
00:05:39,030 --> 00:05:41,006
you that, you know, maybe deliberate spelling

174
00:05:41,066 --> 00:05:42,073
is a sufficiently rare phenomenon

175
00:05:43,050 --> 00:05:44,048
that maybe is not really worth

176
00:05:44,083 --> 00:05:47,012
all your time trying to write

177
00:05:47,070 --> 00:05:48,077
algorithms to detect that.

178
00:05:49,048 --> 00:05:50,048
But if you find a lot

179
00:05:50,077 --> 00:05:52,006
of spammers are using, you

180
00:05:52,013 --> 00:05:54,014
know, unusual punctuation then

181
00:05:54,029 --> 00:05:55,025
maybe that's a strong sign

182
00:05:55,067 --> 00:05:56,073
that it might actually be

183
00:05:57,000 --> 00:05:58,050
worth your while to spend

184
00:05:58,077 --> 00:06:00,027
the time to develop more sophisticated

185
00:06:00,091 --> 00:06:02,018
features based on the punctuation.

186
00:06:03,032 --> 00:06:04,087
So, this sort of error

187
00:06:05,004 --> 00:06:06,038
analysis which is really

188
00:06:06,068 --> 00:06:08,043
the process of manually examining

189
00:06:09,018 --> 00:06:10,054
the mistakes that the algorithm

190
00:06:10,077 --> 00:06:12,022
makes, can often help

191
00:06:12,056 --> 00:06:14,062
guide you to the most fruitful avenues to pursue.

192
00:06:16,000 --> 00:06:17,041
And this also explains why I

193
00:06:17,058 --> 00:06:19,025
often recommend implementing a quick

194
00:06:19,055 --> 00:06:21,025
and dirty implementation of an algorithm.

195
00:06:22,004 --> 00:06:22,093
What we really want to do

196
00:06:23,025 --> 00:06:24,029
is figure out what are

197
00:06:24,031 --> 00:06:26,076
the most difficult examples for an algorithm to classify.

198
00:06:27,086 --> 00:06:29,092
And very often for different

199
00:06:30,045 --> 00:06:31,073
algorithms, for different learning algorithms,

200
00:06:32,000 --> 00:06:33,050
they'll often find, you

201
00:06:33,056 --> 00:06:35,092
know, similar categories of examples difficult.

202
00:06:37,000 --> 00:06:37,097
And by having a quick and

203
00:06:38,006 --> 00:06:39,083
dirty implementation, that's often a

204
00:06:39,091 --> 00:06:40,085
quick way to let you

205
00:06:41,043 --> 00:06:43,006
identify some errors and quickly

206
00:06:43,062 --> 00:06:44,068
identify what are the

207
00:06:44,079 --> 00:06:47,075
hard examples so that you can focus your efforts on those.

208
00:06:49,023 --> 00:06:51,022
Lastly, when developing learning algorithms,

209
00:06:52,025 --> 00:06:53,087
one other useful tip is

210
00:06:54,018 --> 00:06:55,023
to make sure that you have

211
00:06:55,058 --> 00:06:56,044
a way, that you have a

212
00:06:56,081 --> 00:06:59,070
numerical evaluation of your learning algorithm.

213
00:07:02,012 --> 00:07:03,022
Now what I mean by that is that

214
00:07:03,045 --> 00:07:04,067
if you're developing a learning algorithm,

215
00:07:05,023 --> 00:07:07,018
it is often incredibly helpful

216
00:07:08,006 --> 00:07:09,017
if you have a way of

217
00:07:09,045 --> 00:07:10,082
evaluating your learning algorithm

218
00:07:11,029 --> 00:07:13,010
that just gives you back a single real number.

219
00:07:13,064 --> 00:07:14,087
Maybe accuracy, maybe error.

220
00:07:15,062 --> 00:07:18,038
But the single real number that tells you how well your learning algorithm is doing.

221
00:07:20,027 --> 00:07:21,032
I'll talk more about this specific

222
00:07:21,076 --> 00:07:24,064
concepts in later videos, but here's a specific example.

223
00:07:25,079 --> 00:07:26,060
Let's say we are trying to

224
00:07:26,068 --> 00:07:27,099
decide whether or not we

225
00:07:28,006 --> 00:07:29,013
should treat words like discount,

226
00:07:29,058 --> 00:07:32,006
discounts, discounter, discounting, as the same word.

227
00:07:32,037 --> 00:07:33,038
So maybe one way to

228
00:07:33,051 --> 00:07:34,076
do that is to just

229
00:07:35,039 --> 00:07:38,077
look at the first few characters in a word.

230
00:07:38,095 --> 00:07:40,024
Like, you know, if you just look at

231
00:07:40,030 --> 00:07:41,068
the first few characters of

232
00:07:41,077 --> 00:07:44,063
a word, then you figure

233
00:07:44,092 --> 00:07:45,097
out that maybe all of these

234
00:07:46,012 --> 00:07:47,099
words are roughly -   have similar meanings.

235
00:07:50,045 --> 00:07:52,008
In natural language processing, the

236
00:07:52,025 --> 00:07:53,026
way that this is done is

237
00:07:53,050 --> 00:07:55,095
actually using a type of software called stemming software.

238
00:07:56,093 --> 00:07:58,007
If you ever want to do

239
00:07:58,016 --> 00:07:59,087
this yourself, search on a

240
00:07:59,094 --> 00:08:01,024
web search engine for the

241
00:08:01,050 --> 00:08:02,066
Porter Stemmer and that

242
00:08:02,095 --> 00:08:04,031
would be, you know, one reasonable piece of

243
00:08:04,062 --> 00:08:05,082
software for doing this sort

244
00:08:06,011 --> 00:08:07,001
of stemming, which will let

245
00:08:07,012 --> 00:08:08,013
you treat all of these discount,

246
00:08:08,080 --> 00:08:10,054
discounts, and so on as the same word.

247
00:08:13,094 --> 00:08:15,093
But using a stemming software

248
00:08:16,062 --> 00:08:17,070
that basically looks at the

249
00:08:17,082 --> 00:08:19,029
first few alphabets of the

250
00:08:19,044 --> 00:08:21,062
word more or less, it can help but it can hurt.

251
00:08:22,024 --> 00:08:23,049
And it can hurt because, for

252
00:08:23,089 --> 00:08:25,036
example, this software may

253
00:08:25,093 --> 00:08:27,085
mistake the words universe and

254
00:08:27,099 --> 00:08:29,098
university as being the

255
00:08:30,006 --> 00:08:31,022
same thing because, you know,

256
00:08:31,044 --> 00:08:33,022
these two words start off

257
00:08:33,048 --> 00:08:35,048
with very similar characters, with the same alphabets.

258
00:08:37,029 --> 00:08:39,004
So if you're trying

259
00:08:39,027 --> 00:08:40,028
to decide whether or not

260
00:08:40,062 --> 00:08:42,049
to use stemming software for

261
00:08:42,066 --> 00:08:45,096
a stem classifier, it is not always easy to tell.

262
00:08:46,035 --> 00:08:47,080
And in particular, error analysis

263
00:08:48,050 --> 00:08:49,059
may not actually be helpful

264
00:08:51,002 --> 00:08:52,086
for deciding if this

265
00:08:53,005 --> 00:08:54,040
sort of stemming idea is a good idea.

266
00:08:55,057 --> 00:08:56,074
Instead, the best way

267
00:08:57,001 --> 00:08:58,032
to figure out if using stemming

268
00:08:58,069 --> 00:08:59,097
software is good to help

269
00:09:00,019 --> 00:09:01,057
your classifier is if you

270
00:09:01,074 --> 00:09:02,098
have a way to very quickly

271
00:09:03,037 --> 00:09:05,016
just try it and see if it works.

272
00:09:08,055 --> 00:09:09,052
And in order to do this,

273
00:09:10,025 --> 00:09:11,035
having a way to numerically

274
00:09:12,025 --> 00:09:14,057
evaluate your algorithm, is going to be very helpful.

275
00:09:15,094 --> 00:09:17,066
Concretely, maybe the most

276
00:09:18,011 --> 00:09:19,019
natural thing to do is

277
00:09:19,035 --> 00:09:20,025
to look at the cross validation

278
00:09:20,089 --> 00:09:23,050
error of the algorithm's performance with and without stemming.

279
00:09:24,059 --> 00:09:25,055
So, if you run your

280
00:09:25,079 --> 00:09:27,019
algorithm without stemming and you

281
00:09:27,033 --> 00:09:28,042
end up with, let's say,

282
00:09:29,008 --> 00:09:31,025
five percent classification error, and

283
00:09:31,036 --> 00:09:32,040
you re-run it and you

284
00:09:32,053 --> 00:09:33,077
end up with, let's say, three

285
00:09:34,011 --> 00:09:36,016
percent classification error, then this

286
00:09:36,044 --> 00:09:37,091
decrease in error very quickly

287
00:09:38,063 --> 00:09:39,098
allows you to decide that,

288
00:09:40,030 --> 00:09:42,025
you know, it looks like using stemming is a good idea.

289
00:09:43,008 --> 00:09:44,064
For this particular problem, there's

290
00:09:44,094 --> 00:09:46,055
a very natural single real

291
00:09:46,083 --> 00:09:50,021
number evaluation metric, namely, the cross validation error.

292
00:09:50,092 --> 00:09:52,070
We'll see later, examples where coming

293
00:09:53,008 --> 00:09:54,036
up with this, sort of, single

294
00:09:54,078 --> 00:09:58,022
row number evaluation metric may need a little bit more work.

295
00:09:58,078 --> 00:09:59,084
But as we'll see in

296
00:09:59,092 --> 00:10:01,062
the later video, doing so would

297
00:10:01,075 --> 00:10:02,086
also then let you

298
00:10:02,099 --> 00:10:04,028
make these decisions much more quickly

299
00:10:04,075 --> 00:10:06,037
of, say, whether or not to use stemming.

300
00:10:08,070 --> 00:10:09,095
And just this one more quick example.

301
00:10:10,067 --> 00:10:11,066
Let's say that you're also trying

302
00:10:12,003 --> 00:10:13,045
to decide whether or not

303
00:10:13,064 --> 00:10:15,071
to distinguish between upper versus lower case.

304
00:10:15,099 --> 00:10:16,090
So, you know, is the red

305
00:10:17,005 --> 00:10:18,085
mom with uppercase M

306
00:10:19,005 --> 00:10:20,038
versus lower case m,

307
00:10:20,070 --> 00:10:21,072
I mean, should that be treated as

308
00:10:21,077 --> 00:10:23,080
the same word or as different words?

309
00:10:23,097 --> 00:10:26,088
Should these be treated as the same feature or as different features?

310
00:10:27,000 --> 00:10:28,005
And so once again,

311
00:10:28,035 --> 00:10:29,014
because we have a way

312
00:10:29,029 --> 00:10:30,078
to evaluate our algorithm, if

313
00:10:31,005 --> 00:10:32,035
you try this out here, if

314
00:10:32,064 --> 00:10:34,090
I stop distinguishing upper

315
00:10:35,013 --> 00:10:36,049
and lower case, maybe I

316
00:10:36,060 --> 00:10:38,058
end up with 3.2%

317
00:10:38,070 --> 00:10:39,082
error and I find that

318
00:10:40,001 --> 00:10:41,075
therefore this does worse

319
00:10:42,025 --> 00:10:43,036
than, you know, if I use only

320
00:10:43,063 --> 00:10:45,011
stemming, and so this lets

321
00:10:45,037 --> 00:10:47,041
me very quickly decide to go

322
00:10:48,026 --> 00:10:49,072
ahead and to distinguish or to

323
00:10:49,082 --> 00:10:51,053
not distinguish between upper and lower case.

324
00:10:52,013 --> 00:10:53,038
So when you' re developing

325
00:10:53,069 --> 00:10:55,025
a learning algorithm, very often

326
00:10:55,064 --> 00:10:56,084
you'll be trying out lots of

327
00:10:57,004 --> 00:10:59,092
new ideas and lots of new versions of your learning algorithm.

328
00:11:00,096 --> 00:11:02,004
If every time you try

329
00:11:02,035 --> 00:11:03,074
out a new idea if you

330
00:11:03,084 --> 00:11:05,061
end up manually examining a

331
00:11:05,075 --> 00:11:06,073
bunch of examples, you begin to

332
00:11:06,086 --> 00:11:08,052
see better or worse, you

333
00:11:08,063 --> 00:11:09,040
know, that's going to make it

334
00:11:09,058 --> 00:11:10,061
really hard to make decisions

335
00:11:10,098 --> 00:11:12,040
on do you use stemming or not.

336
00:11:12,058 --> 00:11:13,063
Do you distinguish upper or lowercase or not?

337
00:11:15,017 --> 00:11:16,059
But by having a single rule

338
00:11:16,076 --> 00:11:18,051
number evaluation metric, you can

339
00:11:18,067 --> 00:11:21,014
then just look and see oh, did the error go up or go down?

340
00:11:22,041 --> 00:11:23,062
And you can use that much

341
00:11:23,094 --> 00:11:25,075
more rapidly, try out

342
00:11:25,084 --> 00:11:27,082
new ideas and almost right

343
00:11:27,099 --> 00:11:29,054
away tell if your new

344
00:11:29,069 --> 00:11:31,048
idea has improved or worsened

345
00:11:32,044 --> 00:11:33,023
the performance of the learning algorithm

346
00:11:33,092 --> 00:11:35,044
and this will let

347
00:11:35,055 --> 00:11:38,034
you often make much faster progress.

348
00:11:38,052 --> 00:11:39,072
So the recommended, strongly recommended

349
00:11:40,022 --> 00:11:41,078
way to do error analysis is

350
00:11:42,037 --> 00:11:44,075
on the cross validation set rather than the test set.

351
00:11:45,049 --> 00:11:46,097
But, you know, there are

352
00:11:47,024 --> 00:11:48,025
people that will do this on

353
00:11:48,037 --> 00:11:49,048
the test set even though that's

354
00:11:49,073 --> 00:11:51,052
definitely a less mathematically appropriate

355
00:11:52,019 --> 00:11:54,055
set of your list, recommended what

356
00:11:54,073 --> 00:11:55,065
you think to do than to

357
00:11:55,077 --> 00:11:57,024
do error analysis on your

358
00:11:57,045 --> 00:11:58,075
cross validation sector.

359
00:11:59,013 --> 00:12:01,015
So, to wrap up this video, when starting

360
00:12:01,083 --> 00:12:03,034
on the new machine learning problem, what

361
00:12:03,061 --> 00:12:05,037
I almost always recommend is

362
00:12:05,061 --> 00:12:06,092
to implement a quick and

363
00:12:07,002 --> 00:12:08,071
dirty implementation of your learning algorithm.

364
00:12:09,077 --> 00:12:11,075
And I've almost never seen

365
00:12:12,012 --> 00:12:15,037
anyone spend too little time on this quick and dirty implementation.

366
00:12:18,063 --> 00:12:20,021
I pretty much only ever see

367
00:12:20,048 --> 00:12:22,004
people spend much too much

368
00:12:22,037 --> 00:12:23,072
time building their first, you know,

369
00:12:24,058 --> 00:12:25,079
supposedly quick and dirty implementations.

370
00:12:26,059 --> 00:12:28,010
So really, don't worry about

371
00:12:29,007 --> 00:12:31,021
it being too quick, or don't worry about it being too dirty.

372
00:12:32,012 --> 00:12:33,058
But really implement something as

373
00:12:33,069 --> 00:12:35,022
quickly as you can, and once

374
00:12:35,045 --> 00:12:37,054
you have the initial implementation this

375
00:12:37,082 --> 00:12:38,086
is then a powerful tool for

376
00:12:39,023 --> 00:12:40,041
deciding where to spend your

377
00:12:40,061 --> 00:12:42,016
time next, because first we

378
00:12:42,038 --> 00:12:43,038
can look at the errors it makes,

379
00:12:43,062 --> 00:12:44,072
and do this sort of error analysis

380
00:12:45,027 --> 00:12:46,036
to see what mistakes it makes

381
00:12:47,000 --> 00:12:48,041
and use that to inspire further development.

382
00:12:49,002 --> 00:12:50,087
And second, assuming your

383
00:12:51,000 --> 00:12:53,036
quick and dirty implementation incorporated a

384
00:12:53,062 --> 00:12:55,070
single real number evaluation metric, this

385
00:12:55,094 --> 00:12:57,065
can then be a vehicle for

386
00:12:57,073 --> 00:12:58,098
you to try out different ideas

387
00:12:59,080 --> 00:13:00,080
and quickly see if the

388
00:13:01,002 --> 00:13:02,016
different ideas you're trying out

389
00:13:02,044 --> 00:13:03,083
are improving the performance of

390
00:13:03,091 --> 00:13:05,041
your algorithm and therefore let

391
00:13:05,057 --> 00:13:06,047
you maybe much more quickly

392
00:13:06,086 --> 00:13:08,044
make decisions about what things

393
00:13:08,075 --> 00:13:09,089
to fold, and what things to

394
00:13:10,024 --> 00:13:11,051
incorporate into your learning algorithm.
