
1
00:00:00,037 --> 00:00:01,059
In the previous video, we talked

2
00:00:01,088 --> 00:00:04,057
about the photo OCR pipeline and how that worked.

3
00:00:05,048 --> 00:00:06,037
In which we would take an image

4
00:00:07,004 --> 00:00:08,007
and pass the Through a

5
00:00:08,013 --> 00:00:10,000
sequence of machine learning

6
00:00:10,027 --> 00:00:11,067
components in order to

7
00:00:11,089 --> 00:00:13,082
try to read the text that appears in an image.

8
00:00:14,058 --> 00:00:15,082
In this video I like to.

9
00:00:16,021 --> 00:00:17,035
A little bit more about how the

10
00:00:17,078 --> 00:00:20,030
individual components of the pipeline works.

11
00:00:21,026 --> 00:00:24,007
In particular most of this video will center around the discussion.

12
00:00:24,067 --> 00:00:25,094
of whats called a sliding windows.

13
00:00:26,075 --> 00:00:31,057
The first stage

14
00:00:32,000 --> 00:00:33,039
of the filter was the

15
00:00:33,072 --> 00:00:35,009
Text detection where we look

16
00:00:35,032 --> 00:00:36,064
at an image like this and try

17
00:00:37,002 --> 00:00:39,032
to find the regions of text that appear in this image.

18
00:00:39,085 --> 00:00:42,049
Text detection is an unusual problem in computer vision.

19
00:00:43,021 --> 00:00:44,082
Because depending on the length

20
00:00:45,014 --> 00:00:46,014
of the text you're trying to

21
00:00:46,028 --> 00:00:47,086
find, these rectangles that you're

22
00:00:47,096 --> 00:00:49,060
trying to find can have different aspect.

23
00:00:51,010 --> 00:00:52,006
So in order to talk

24
00:00:52,021 --> 00:00:53,054
about detecting things in images

25
00:00:54,029 --> 00:00:55,085
let's start with a simpler example

26
00:00:56,054 --> 00:01:00,007
of pedestrian detection and we'll then later go back to.

27
00:01:00,046 --> 00:01:02,029
Ideas that were developed

28
00:01:02,057 --> 00:01:04,084
in pedestrian detection and apply them to text detection.

29
00:01:06,028 --> 00:01:08,001
So in pedestrian detection you want

30
00:01:08,035 --> 00:01:09,043
to take an image that looks

31
00:01:09,059 --> 00:01:11,001
like this and the whole

32
00:01:11,015 --> 00:01:12,092
idea is the individual pedestrians that appear in the image.

33
00:01:13,026 --> 00:01:14,043
So there's one pedestrian that we

34
00:01:14,051 --> 00:01:15,054
found, there's a second

35
00:01:15,078 --> 00:01:17,092
one, a third one a fourth one, a fifth one.

36
00:01:18,029 --> 00:01:19,039
And a one.

37
00:01:19,056 --> 00:01:20,098
This problem is maybe slightly

38
00:01:21,031 --> 00:01:22,076
simpler than text detection just

39
00:01:23,009 --> 00:01:24,020
for the reason that the aspect

40
00:01:24,056 --> 00:01:27,048
ratio of most pedestrians are pretty similar.

41
00:01:28,017 --> 00:01:29,028
Just using a fixed aspect

42
00:01:29,062 --> 00:01:31,095
ratio for these rectangles that we're trying to find.

43
00:01:32,042 --> 00:01:33,060
So by aspect ratio I mean

44
00:01:33,092 --> 00:01:36,042
the ratio between the height and the width of these rectangles.

45
00:01:37,081 --> 00:01:38,018
They're all the same.

46
00:01:38,065 --> 00:01:40,012
for different pedestrians but for

47
00:01:40,048 --> 00:01:42,065
text detection the height

48
00:01:43,003 --> 00:01:44,056
and width ratio is different

49
00:01:44,095 --> 00:01:45,082
for different lines of text

50
00:01:46,045 --> 00:01:47,093
Although for pedestrian detection, the

51
00:01:48,001 --> 00:01:49,025
pedestrians can be different distances

52
00:01:49,081 --> 00:01:51,025
away from the camera and

53
00:01:51,039 --> 00:01:52,073
so the height of these rectangles

54
00:01:53,037 --> 00:01:55,059
can be different depending on how far away they are.

55
00:01:55,098 --> 00:01:57,009
but the aspect ratio is the same.

56
00:01:57,071 --> 00:01:58,087
In order to build a pedestrian

57
00:01:59,043 --> 00:02:02,045
detection system here's how you can go about it.

58
00:02:02,051 --> 00:02:03,065
Let's say that we decide to

59
00:02:03,096 --> 00:02:06,009
standardize on this aspect

60
00:02:06,068 --> 00:02:08,000
ratio of 82 by 36

61
00:02:08,018 --> 00:02:10,003
and we could

62
00:02:10,033 --> 00:02:11,050
have chosen some rounded number

63
00:02:12,002 --> 00:02:14,000
like 80 by 40 or something, but 82 by 36 seems alright.

64
00:02:16,011 --> 00:02:17,028
What we would do is then go

65
00:02:17,065 --> 00:02:20,041
out and collect large training sets of positive and negative examples.

66
00:02:21,024 --> 00:02:22,078
Here are examples of 82

67
00:02:22,090 --> 00:02:24,022
X 36 image patches that do

68
00:02:24,036 --> 00:02:26,022
contain pedestrians and here are

69
00:02:26,055 --> 00:02:28,036
examples of images that do not.

70
00:02:29,046 --> 00:02:30,071
On this slide I show 12

71
00:02:31,005 --> 00:02:33,016
positive examples of y1

72
00:02:33,072 --> 00:02:34,099
and 12 examples of y0.

73
00:02:36,040 --> 00:02:37,078
In a more typical pedestrian detection

74
00:02:38,018 --> 00:02:39,019
application, we may have

75
00:02:39,050 --> 00:02:40,087
anywhere from a 1,000 training

76
00:02:41,022 --> 00:02:42,021
examples up to maybe

77
00:02:42,030 --> 00:02:44,040
10,000 training examples, or

78
00:02:44,046 --> 00:02:45,036
even more if you can

79
00:02:45,050 --> 00:02:47,018
get even larger training sets.

80
00:02:47,046 --> 00:02:48,059
And what you can do, is then train

81
00:02:48,090 --> 00:02:50,015
in your network or some

82
00:02:50,050 --> 00:02:52,041
other learning algorithm to

83
00:02:52,061 --> 00:02:54,056
take this input, an MS

84
00:02:54,096 --> 00:02:56,071
patch of dimension 82 by

85
00:02:56,084 --> 00:02:59,018
36, and to classify  'y'

86
00:02:59,071 --> 00:03:01,006
and to classify that image patch

87
00:03:01,050 --> 00:03:03,084
as either containing a pedestrian or not.

88
00:03:05,025 --> 00:03:06,025
So this gives you a way

89
00:03:06,046 --> 00:03:08,005
of applying supervised learning in

90
00:03:08,021 --> 00:03:09,028
order to take an image

91
00:03:09,053 --> 00:03:12,041
patch can determine whether or not a pedestrian appears in that image capture.

92
00:03:14,031 --> 00:03:15,018
Now, lets say we get

93
00:03:15,040 --> 00:03:16,052
a new image, a test set

94
00:03:16,084 --> 00:03:17,091
image like this and we

95
00:03:18,003 --> 00:03:20,024
want to try to find a pedestrian's picture image.

96
00:03:21,052 --> 00:03:22,034
What we would do is start

97
00:03:22,066 --> 00:03:25,013
by taking a rectangular patch of this image.

98
00:03:25,058 --> 00:03:26,080
Like that shown up here, so

99
00:03:26,090 --> 00:03:27,093
that's maybe a 82 X

100
00:03:28,000 --> 00:03:29,043
36 patch of this image,

101
00:03:30,027 --> 00:03:31,053
and run that image patch through

102
00:03:31,083 --> 00:03:33,065
our classifier to determine whether

103
00:03:33,084 --> 00:03:34,090
or not there is a

104
00:03:34,097 --> 00:03:36,031
pedestrian in that image patch,

105
00:03:36,062 --> 00:03:38,009
and hopefully our classifier will

106
00:03:38,025 --> 00:03:40,059
return y equals 0 for that patch, since there is no pedestrian.

107
00:03:42,002 --> 00:03:42,090
Next, we then take that green

108
00:03:43,013 --> 00:03:44,037
rectangle and we slide it

109
00:03:44,049 --> 00:03:45,068
over a bit and then

110
00:03:45,093 --> 00:03:47,018
run that new image patch

111
00:03:47,056 --> 00:03:49,069
through our classifier to decide if there's a pedestrian there.

112
00:03:50,075 --> 00:03:51,074
And having done that, we then

113
00:03:51,091 --> 00:03:53,006
slide the window further to the

114
00:03:53,015 --> 00:03:54,015
right and run that patch

115
00:03:54,041 --> 00:03:56,068
through the classifier again.

116
00:03:56,096 --> 00:03:57,084
The amount by which you shift

117
00:03:58,028 --> 00:03:59,077
the rectangle over each time

118
00:04:00,025 --> 00:04:01,071
is a parameter, that's sometimes

119
00:04:02,018 --> 00:04:04,000
called the step size of the

120
00:04:04,006 --> 00:04:06,002
parameter, sometimes also called

121
00:04:06,037 --> 00:04:08,096
the slide parameter, and if

122
00:04:09,012 --> 00:04:11,005
you step this one pixel at a time.

123
00:04:11,021 --> 00:04:12,002
So you can use the step size

124
00:04:12,036 --> 00:04:14,002
or stride of 1, that usually

125
00:04:14,034 --> 00:04:15,056
performs best, that is

126
00:04:15,069 --> 00:04:16,095
more cost effective, and

127
00:04:17,043 --> 00:04:18,093
so using a step size of

128
00:04:19,008 --> 00:04:20,000
maybe 4 pixels at a

129
00:04:20,020 --> 00:04:20,097
time, or eight pixels at a

130
00:04:21,025 --> 00:04:22,035
time or some large number of

131
00:04:22,055 --> 00:04:23,060
pixels might be more common,

132
00:04:24,000 --> 00:04:25,031
since you're then moving the

133
00:04:25,043 --> 00:04:26,056
rectangle a little bit

134
00:04:26,069 --> 00:04:28,056
more each time.

135
00:04:28,087 --> 00:04:30,008
So, using this process, you continue

136
00:04:30,087 --> 00:04:32,031
stepping the rectangle over to

137
00:04:32,033 --> 00:04:33,016
the right a bit at a

138
00:04:33,037 --> 00:04:34,044
time and running each of

139
00:04:34,051 --> 00:04:35,077
these patches through a classifier,

140
00:04:36,062 --> 00:04:38,022
until eventually, as you

141
00:04:38,089 --> 00:04:42,007
slide this window over the

142
00:04:42,014 --> 00:04:43,033
different locations in the image,

143
00:04:43,055 --> 00:04:44,068
first starting with the first

144
00:04:44,085 --> 00:04:46,007
row and then we

145
00:04:46,016 --> 00:04:47,057
go further rows in

146
00:04:47,070 --> 00:04:49,010
the image, you would

147
00:04:49,029 --> 00:04:50,049
then run all of

148
00:04:50,055 --> 00:04:52,006
these different image patches at

149
00:04:52,024 --> 00:04:53,032
some step size or some

150
00:04:53,043 --> 00:04:54,099
stride through your classifier.

151
00:04:56,099 --> 00:04:57,087
Now, that was a pretty

152
00:04:57,097 --> 00:04:59,087
small rectangle, that would only

153
00:05:00,031 --> 00:05:02,031
detect pedestrians of one specific size.

154
00:05:02,077 --> 00:05:04,020
What we do next is

155
00:05:04,047 --> 00:05:05,099
start to look at larger image patches.

156
00:05:06,073 --> 00:05:08,026
So now let's take larger images

157
00:05:08,061 --> 00:05:09,069
patches, like those shown here

158
00:05:10,031 --> 00:05:11,095
and run those through the crossfire as well.

159
00:05:13,054 --> 00:05:14,031
And by the way when I say

160
00:05:14,060 --> 00:05:15,082
take a larger image patch, what

161
00:05:16,007 --> 00:05:17,077
I really mean is when you

162
00:05:17,086 --> 00:05:18,085
take an image patch like this,

163
00:05:19,049 --> 00:05:20,072
what you're really doing is taking

164
00:05:20,087 --> 00:05:22,011
that image patch, and resizing

165
00:05:22,080 --> 00:05:24,075
it down to 82 X 36, say.

166
00:05:25,000 --> 00:05:26,025
So you take this larger

167
00:05:26,055 --> 00:05:28,018
patch and re-size it to

168
00:05:28,030 --> 00:05:29,080
be smaller image and then

169
00:05:29,097 --> 00:05:31,025
it would be the smaller size image

170
00:05:31,060 --> 00:05:32,062
that is what you

171
00:05:32,099 --> 00:05:35,033
would pass through your classifier to try and decide if there is a pedestrian in that patch.

172
00:05:37,023 --> 00:05:38,031
And finally you can do

173
00:05:38,047 --> 00:05:39,052
this at an even larger

174
00:05:39,093 --> 00:05:41,087
scales and run

175
00:05:42,007 --> 00:05:43,082
that side of Windows to

176
00:05:43,098 --> 00:05:45,092
the end And after

177
00:05:45,098 --> 00:05:47,048
this whole process hopefully your algorithm

178
00:05:48,004 --> 00:05:49,067
will detect whether theres pedestrian

179
00:05:50,013 --> 00:05:52,006
appears in the image, so

180
00:05:52,047 --> 00:05:53,085
thats how you train a

181
00:05:54,029 --> 00:05:55,062
the classifier, and then

182
00:05:55,088 --> 00:05:57,036
use a sliding windows classifier,

183
00:05:57,092 --> 00:05:59,081
or use a sliding windows detector in

184
00:05:59,097 --> 00:06:01,074
order to find pedestrians in the image.

185
00:06:03,006 --> 00:06:04,005
Let's have a turn to the

186
00:06:04,014 --> 00:06:05,091
text detection example and talk

187
00:06:06,010 --> 00:06:07,049
about that stage in our

188
00:06:07,079 --> 00:06:09,032
photo OCR pipeline, where our

189
00:06:09,056 --> 00:06:11,033
goal is to find the text regions in unit.

190
00:06:13,025 --> 00:06:15,000
similar to pedestrian detection you

191
00:06:15,025 --> 00:06:16,073
can come up with a label

192
00:06:17,002 --> 00:06:18,041
training set with positive examples

193
00:06:19,006 --> 00:06:20,093
and negative examples with examples

194
00:06:21,052 --> 00:06:23,081
corresponding to regions where text appears.

195
00:06:24,030 --> 00:06:27,029
So instead of trying to detect pedestrians, we're now trying to detect texts.

196
00:06:28,012 --> 00:06:29,067
And so positive examples are going

197
00:06:29,076 --> 00:06:31,063
to be patches of images where there is text.

198
00:06:31,097 --> 00:06:33,032
And negative examples is going

199
00:06:33,037 --> 00:06:36,000
to be patches of images where there isn't text.

200
00:06:36,032 --> 00:06:37,052
Having trained this we can

201
00:06:38,002 --> 00:06:39,044
now apply it to a

202
00:06:39,087 --> 00:06:41,018
new image, into a test

203
00:06:42,045 --> 00:06:42,091
set image.

204
00:06:43,031 --> 00:06:44,089
So here's the image that we've been using as example.

205
00:06:46,004 --> 00:06:47,030
Now, last time we run,

206
00:06:47,043 --> 00:06:48,039
for this example we are going

207
00:06:48,056 --> 00:06:50,030
to run a sliding windows at

208
00:06:50,063 --> 00:06:52,002
just one fixed scale just

209
00:06:52,037 --> 00:06:54,036
for purpose of illustration, meaning that

210
00:06:54,044 --> 00:06:56,000
I'm going to use just one rectangle size.

211
00:06:56,079 --> 00:06:58,011
But lets say I run my little

212
00:06:58,035 --> 00:07:00,006
sliding windows classifier on lots

213
00:07:00,017 --> 00:07:01,056
of little image patches like

214
00:07:01,062 --> 00:07:04,033
this if I

215
00:07:04,043 --> 00:07:05,043
do that, what Ill end

216
00:07:05,052 --> 00:07:06,067
up with is a result

217
00:07:07,004 --> 00:07:08,052
like this where the white

218
00:07:08,089 --> 00:07:10,069
region show where my

219
00:07:10,093 --> 00:07:12,018
text detection system has found

220
00:07:12,020 --> 00:07:15,095
text and so the axis' of these two figures are the same.

221
00:07:16,038 --> 00:07:17,069
So there is a region

222
00:07:18,011 --> 00:07:19,019
up here, of course also

223
00:07:19,023 --> 00:07:20,070
a region up here, so the

224
00:07:20,083 --> 00:07:22,004
fact that this black up here

225
00:07:22,085 --> 00:07:24,038
represents that the classifier

226
00:07:24,083 --> 00:07:25,093
does not think it's found any

227
00:07:26,017 --> 00:07:28,010
texts up there, whereas the

228
00:07:28,017 --> 00:07:29,062
fact that there's a lot

229
00:07:29,081 --> 00:07:31,030
of white stuff here, that reflects that

230
00:07:31,054 --> 00:07:33,025
classifier thinks that it's found a bunch of texts.

231
00:07:33,051 --> 00:07:34,031
over there on the image.

232
00:07:35,004 --> 00:07:35,069
What i have done on this

233
00:07:35,077 --> 00:07:36,087
image on the lower left is

234
00:07:37,006 --> 00:07:38,081
actually use white to

235
00:07:38,097 --> 00:07:41,005
show where the classifier thinks it has found text.

236
00:07:41,081 --> 00:07:43,027
And different shades of grey

237
00:07:43,087 --> 00:07:45,056
correspond to the probability that

238
00:07:45,067 --> 00:07:46,075
was output by the classifier,

239
00:07:47,011 --> 00:07:48,000
so like the shades of grey

240
00:07:48,051 --> 00:07:49,086
corresponds to where it

241
00:07:49,093 --> 00:07:50,075
thinks it might have found text

242
00:07:51,020 --> 00:07:53,089
but has lower confidence the bright

243
00:07:54,025 --> 00:07:55,098
white response to whether the classifier,

244
00:07:57,043 --> 00:07:58,039
up with a very high

245
00:07:58,066 --> 00:08:00,047
probability, estimated probability of

246
00:08:00,062 --> 00:08:03,011
there being pedestrians in that location.

247
00:08:04,011 --> 00:08:05,026
We aren't quite done yet because

248
00:08:05,068 --> 00:08:06,057
what we actually want to do

249
00:08:06,082 --> 00:08:08,062
is draw rectangles around all

250
00:08:08,085 --> 00:08:09,077
the region where this text

251
00:08:10,049 --> 00:08:12,054
in the image, so were

252
00:08:12,064 --> 00:08:13,054
going to take one more step

253
00:08:13,083 --> 00:08:14,099
which is we take the output

254
00:08:15,023 --> 00:08:16,087
of the classifier and apply

255
00:08:17,029 --> 00:08:19,027
to it what is called an expansion operator.

256
00:08:20,075 --> 00:08:22,025
So what that does is, it

257
00:08:22,043 --> 00:08:24,026
take the image here,

258
00:08:25,044 --> 00:08:26,069
and it takes each of

259
00:08:26,080 --> 00:08:28,019
the white blobs, it takes each

260
00:08:28,026 --> 00:08:30,058
of the white regions and it expands that white region.

261
00:08:31,045 --> 00:08:32,046
Mathematically, the way you

262
00:08:32,061 --> 00:08:34,011
implement that is, if you

263
00:08:34,026 --> 00:08:35,027
look at the image on the right, what

264
00:08:35,069 --> 00:08:36,077
we're doing to create the

265
00:08:36,092 --> 00:08:38,011
image on the right is, for every

266
00:08:38,037 --> 00:08:39,050
pixel we are going

267
00:08:39,061 --> 00:08:40,078
to ask, is it withing

268
00:08:41,037 --> 00:08:42,096
some distance of a

269
00:08:43,010 --> 00:08:44,064
white pixel in the left image.

270
00:08:45,042 --> 00:08:46,079
And so, if a specific pixel

271
00:08:47,022 --> 00:08:48,041
is within, say, five pixels

272
00:08:48,095 --> 00:08:50,027
or ten pixels of a white

273
00:08:50,061 --> 00:08:52,030
pixel in the leftmost image, then

274
00:08:52,053 --> 00:08:55,001
we'll also color that pixel white in the rightmost image.

275
00:08:56,019 --> 00:08:57,000
And so, the effect of this

276
00:08:57,029 --> 00:08:58,035
is, we'll take each of the

277
00:08:58,073 --> 00:08:59,062
white blobs in the leftmost

278
00:09:00,002 --> 00:09:01,037
image and expand them a

279
00:09:01,050 --> 00:09:02,020
bit, grow them a little

280
00:09:02,066 --> 00:09:04,011
bit, by seeing whether the

281
00:09:04,016 --> 00:09:05,041
nearby pixels, the white pixels,

282
00:09:05,089 --> 00:09:07,098
and then coloring those nearby pixels in white as well.

283
00:09:08,042 --> 00:09:09,089
Finally, we are just about done.

284
00:09:10,017 --> 00:09:11,021
We can now look at this

285
00:09:11,048 --> 00:09:12,089
right most image and just

286
00:09:13,021 --> 00:09:14,064
look at the connecting components

287
00:09:15,032 --> 00:09:16,070
and look at the as white

288
00:09:16,099 --> 00:09:19,035
regions and draw bounding boxes around them.

289
00:09:20,025 --> 00:09:20,099
And in particular, if we look at

290
00:09:21,038 --> 00:09:22,085
all the white regions, like

291
00:09:23,008 --> 00:09:24,075
this one, this one, this

292
00:09:24,099 --> 00:09:26,066
one, and so on, and

293
00:09:27,002 --> 00:09:27,080
if we use a simple heuristic

294
00:09:28,038 --> 00:09:30,024
to rule out rectangles whose aspect

295
00:09:30,065 --> 00:09:32,075
ratios look funny because we

296
00:09:32,087 --> 00:09:34,046
know that boxes around text

297
00:09:34,073 --> 00:09:36,012
should be much wider than they are tall.

298
00:09:37,011 --> 00:09:38,030
And so if we ignore the

299
00:09:38,040 --> 00:09:39,099
thin, tall blobs like this one

300
00:09:40,023 --> 00:09:42,012
and this one, and

301
00:09:42,019 --> 00:09:43,038
we discard these ones because

302
00:09:43,087 --> 00:09:45,049
they are too tall and thin, and

303
00:09:45,065 --> 00:09:46,077
we then draw a the rectangles

304
00:09:47,047 --> 00:09:48,044
around the ones whose aspect

305
00:09:48,084 --> 00:09:50,041
ratio thats a height

306
00:09:50,061 --> 00:09:51,079
to what ratio looks like for

307
00:09:51,095 --> 00:09:53,030
text regions, then we

308
00:09:53,037 --> 00:09:55,007
can draw rectangles, the bounding

309
00:09:55,045 --> 00:09:56,065
boxes around this text

310
00:09:56,097 --> 00:09:58,050
region, this text region, and

311
00:09:58,061 --> 00:10:00,054
that text region, corresponding to

312
00:10:01,005 --> 00:10:02,017
the Lula B's antique mall logo,

313
00:10:02,064 --> 00:10:04,069
the Lula B's, and this little open sign.

314
00:10:05,084 --> 00:10:06,000
Of over there.

315
00:10:07,010 --> 00:10:09,054
This example by the actually misses one piece of text.

316
00:10:09,086 --> 00:10:12,054
This is very hard to read, but there is actually one piece of text there.

317
00:10:13,008 --> 00:10:14,071
That says [xx] are corresponding

318
00:10:14,095 --> 00:10:16,017
to this but the aspect ratio

319
00:10:16,052 --> 00:10:17,096
looks wrong so we discarded that one.

320
00:10:19,010 --> 00:10:20,024
So you know it's ok

321
00:10:20,052 --> 00:10:21,046
on this image, but in

322
00:10:21,065 --> 00:10:22,075
this particular example the classifier

323
00:10:23,028 --> 00:10:24,039
actually missed one piece of text.

324
00:10:24,075 --> 00:10:25,077
It's very hard to read because

325
00:10:25,096 --> 00:10:26,089
there's a piece of text

326
00:10:27,024 --> 00:10:28,070
written against a transparent window.

327
00:10:29,075 --> 00:10:31,020
So that's text detection

328
00:10:32,042 --> 00:10:33,012
using sliding windows.

329
00:10:33,079 --> 00:10:35,029
And having found these rectangles

330
00:10:36,010 --> 00:10:37,000
with the text in it, we

331
00:10:37,011 --> 00:10:38,024
can now just cut out

332
00:10:38,045 --> 00:10:39,088
these image regions and then

333
00:10:40,007 --> 00:10:42,010
use later stages of pipeline to try to meet the texts.

334
00:10:45,038 --> 00:10:46,082
Now, you recall that the

335
00:10:46,087 --> 00:10:48,036
second stage of pipeline was

336
00:10:48,057 --> 00:10:50,062
character segmentation, so given an

337
00:10:50,088 --> 00:10:52,052
image like that shown on top,

338
00:10:52,078 --> 00:10:55,065
how do we segment out the individual characters in this image?

339
00:10:56,058 --> 00:10:57,046
So what we can do is

340
00:10:57,090 --> 00:10:59,059
again use a supervised learning

341
00:11:00,000 --> 00:11:01,001
algorithm with some set of

342
00:11:01,010 --> 00:11:01,099
positive and some set of

343
00:11:02,010 --> 00:11:03,080
negative examples, what were

344
00:11:03,087 --> 00:11:04,084
going to do is look in

345
00:11:04,089 --> 00:11:06,015
the image patch and try

346
00:11:06,038 --> 00:11:08,011
to decide if there

347
00:11:08,037 --> 00:11:09,069
is split between two characters

348
00:11:10,070 --> 00:11:12,007
right in the middle of that image match.

349
00:11:13,002 --> 00:11:14,010
So for initial positive examples.

350
00:11:14,096 --> 00:11:17,003
This first cross example, this image

351
00:11:17,028 --> 00:11:18,059
patch looks like the

352
00:11:18,064 --> 00:11:20,004
middle of it is indeed

353
00:11:21,032 --> 00:11:22,088
the middle has splits between two

354
00:11:23,011 --> 00:11:24,012
characters and the second example

355
00:11:24,067 --> 00:11:25,076
again this looks like a

356
00:11:25,095 --> 00:11:27,037
positive example, because if I split

357
00:11:27,084 --> 00:11:29,001
two characters by putting a

358
00:11:29,015 --> 00:11:31,019
line right down the middle, that's the right thing to do.

359
00:11:31,035 --> 00:11:33,030
So, these are positive examples, where

360
00:11:33,050 --> 00:11:35,037
the middle of the image represents

361
00:11:35,097 --> 00:11:36,092
a gap or a split

362
00:11:37,096 --> 00:11:40,032
between two distinct characters, whereas

363
00:11:40,055 --> 00:11:41,087
the negative examples, well, you

364
00:11:42,000 --> 00:11:43,015
know, you don't want to split

365
00:11:43,069 --> 00:11:44,080
two characters right in the

366
00:11:44,089 --> 00:11:46,061
middle, and so

367
00:11:46,082 --> 00:11:48,015
these are negative examples because

368
00:11:48,046 --> 00:11:50,065
they don't represent the midpoint between two characters.

369
00:11:51,075 --> 00:11:52,049
So what we will do

370
00:11:52,064 --> 00:11:53,094
is, we will train a classifier,

371
00:11:54,050 --> 00:11:55,090
maybe using new network, maybe

372
00:11:56,017 --> 00:11:58,000
using a different learning algorithm, to

373
00:11:58,012 --> 00:12:01,041
try to classify between the positive and negative examples.

374
00:12:02,076 --> 00:12:03,098
Having trained such a classifier,

375
00:12:04,032 --> 00:12:06,002
we can then run this on

376
00:12:06,069 --> 00:12:07,083
this sort of text that our

377
00:12:07,094 --> 00:12:09,040
text detection system has pulled out.

378
00:12:09,059 --> 00:12:10,097
As we start by looking at

379
00:12:11,012 --> 00:12:12,008
that rectangle, and we ask,

380
00:12:12,023 --> 00:12:13,027
"Gee, does it look

381
00:12:13,050 --> 00:12:15,000
like the middle of

382
00:12:15,010 --> 00:12:16,060
that green rectangle, does it

383
00:12:16,067 --> 00:12:18,047
look like the midpoint between two characters?".

384
00:12:18,098 --> 00:12:18,047


385
00:12:18,098 --> 00:12:20,022
And hopefully, the classifier will

386
00:12:20,032 --> 00:12:21,075
say no, then we slide

387
00:12:22,016 --> 00:12:23,027
the window over and this

388
00:12:23,040 --> 00:12:24,085
is a one dimensional sliding

389
00:12:25,020 --> 00:12:26,040
window classifier, because were

390
00:12:26,050 --> 00:12:27,082
going to slide the window only

391
00:12:28,047 --> 00:12:29,055
in one straight line from

392
00:12:29,077 --> 00:12:32,007
left to right, theres no different rows here.

393
00:12:32,026 --> 00:12:34,041
There's only one row here.

394
00:12:34,051 --> 00:12:36,015
But now, with the classifier in

395
00:12:36,024 --> 00:12:37,025
this position, we ask, well,

396
00:12:37,049 --> 00:12:38,070
should we split those two characters

397
00:12:39,057 --> 00:12:41,058
or should we put a split right down the middle of this rectangle.

398
00:12:41,095 --> 00:12:43,003
And hopefully, the classifier will

399
00:12:43,019 --> 00:12:44,072
output y equals one, in

400
00:12:44,077 --> 00:12:46,046
which case we will decide to

401
00:12:46,062 --> 00:12:49,069
draw a line down there, to try to split two characters.

402
00:12:50,071 --> 00:12:51,062
Then we slide the window over

403
00:12:51,087 --> 00:12:53,044
again, optic process, don't

404
00:12:53,064 --> 00:12:55,001
close the gap, slide over again,

405
00:12:55,029 --> 00:12:56,058
optic says yes, do split

406
00:12:57,023 --> 00:12:58,083
there and so

407
00:12:59,020 --> 00:13:00,040
on, and we slowly slide the

408
00:13:00,055 --> 00:13:01,076
classifier over to the

409
00:13:01,091 --> 00:13:03,030
right and hopefully it will

410
00:13:03,037 --> 00:13:05,015
classify this as another positive example and

411
00:13:05,076 --> 00:13:07,047
so on.

412
00:13:08,000 --> 00:13:09,017
And we will slide this window

413
00:13:09,082 --> 00:13:10,099
over to the right, running the

414
00:13:11,015 --> 00:13:12,066
classifier at every step, and

415
00:13:12,079 --> 00:13:13,079
hopefully it will tell us,

416
00:13:14,021 --> 00:13:15,007
you know, what are the right locations

417
00:13:16,019 --> 00:13:17,082
to split these characters up into,

418
00:13:18,028 --> 00:13:20,040
just split this image up into individual characters.

419
00:13:21,009 --> 00:13:22,045
And so thats 1D sliding

420
00:13:22,080 --> 00:13:24,019
windows for character segmentation.

421
00:13:25,051 --> 00:13:28,042
So, here's the overall photo OCR pipe line again.

422
00:13:29,012 --> 00:13:30,027
In this video we've talked about

423
00:13:30,077 --> 00:13:32,016
the text detection step, where

424
00:13:32,036 --> 00:13:34,057
we use sliding windows to detect text.

425
00:13:35,020 --> 00:13:36,038
And we also use a one-dimensional

426
00:13:37,007 --> 00:13:38,041
sliding windows to do character

427
00:13:38,078 --> 00:13:40,015
segmentation to segment out,

428
00:13:40,073 --> 00:13:42,086
you know, this text image in division of characters.

429
00:13:43,089 --> 00:13:44,076
The final step through the

430
00:13:44,080 --> 00:13:46,003
pipeline is the character qualification

431
00:13:46,072 --> 00:13:48,014
step and that step you might

432
00:13:48,037 --> 00:13:49,075
already be much more familiar

433
00:13:50,001 --> 00:13:51,049
with the early videos

434
00:13:52,008 --> 00:13:54,047
on supervised learning

435
00:13:55,016 --> 00:13:56,044
where you can apply a standard

436
00:13:56,094 --> 00:13:58,014
supervised learning within maybe

437
00:13:58,036 --> 00:13:59,025
on your network or maybe something

438
00:13:59,057 --> 00:14:00,064
else in order to

439
00:14:00,086 --> 00:14:02,010
take it's input, an image

440
00:14:02,098 --> 00:14:05,002
like that and classify which alphabet

441
00:14:05,048 --> 00:14:07,012
or which 26 characters A

442
00:14:07,023 --> 00:14:08,032
to Z, or maybe we should

443
00:14:08,057 --> 00:14:09,066
have 36 characters if you

444
00:14:09,077 --> 00:14:11,013
have the numerical digits as

445
00:14:11,026 --> 00:14:12,064
well, the multi class

446
00:14:13,008 --> 00:14:14,040
classification problem where you

447
00:14:14,050 --> 00:14:15,069
take it's input and image

448
00:14:16,004 --> 00:14:17,038
contained a character and decide

449
00:14:18,013 --> 00:14:20,045
what is the character that appears in that image?

450
00:14:21,008 --> 00:14:22,046
So that was the photo OCR

451
00:14:23,073 --> 00:14:24,075
pipeline and how you can

452
00:14:24,090 --> 00:14:26,013
use ideas like sliding windows

453
00:14:26,051 --> 00:14:27,096
classifiers in order to

454
00:14:28,010 --> 00:14:29,078
put these different components to

455
00:14:30,005 --> 00:14:31,057
develop a photo OCR system.

456
00:14:32,042 --> 00:14:33,057
In the next few videos we

457
00:14:33,067 --> 00:14:34,092
keep on using the problem of

458
00:14:35,014 --> 00:14:36,054
photo OCR to explore somewhat

459
00:14:36,096 --> 00:14:39,007
interesting issues surrounding building an application like this.
